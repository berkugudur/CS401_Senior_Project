{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# For using core package that located in the two upper folder.\n",
    "import os,sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from core.json_importer import parse_json_file, parse_all_files\n",
    "from core.filters import remove_both_standing_frames, remove_same_consecutive_actions, remove_recov_frames, remove_unchange_hp\n",
    "from core.actions import one_hot_encode, one_hot_encode_hpdif, decode\n",
    "from core.preproccessing import Normalizer\n",
    "from core.helpers import write_file\n",
    "from core.visualizer import plot_confusion_matrix\n",
    "from util.AIConnection.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create out file folder if not exists\n",
    "OUT_FOLDER = 'generated_files'\n",
    "if not os.path.exists(OUT_FOLDER):\n",
    "    os.makedirs(OUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open files\n",
    "training_data = parse_all_files(\"data/trainbcp15/\")\n",
    "testing_data = parse_all_files(\"data/trainbcp5/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6116 train data.(155884 deleted.)\n",
      "There are 1948 test data.(52052 deleted.)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply filters for training data\n",
    "tr_deleted = training_data.filter(remove_unchange_hp)\n",
    "\n",
    "# Apply filters for training data\n",
    "te_deleted = testing_data.filter(remove_unchange_hp)\n",
    "\n",
    "\n",
    "print('There are {} train data.({} deleted.)'.format(len(training_data), tr_deleted))\n",
    "print('There are {} test data.({} deleted.)'.format(len(testing_data), te_deleted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 rounds and 6116 frames.\n"
     ]
    }
   ],
   "source": [
    "print(training_data)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp values are -5 -4 -3 -2 -1 0 1 2 3 4 5\n",
    "# and they are one hot encoding index 0 to index 10\n",
    "# so, when we argmax to predicted result, if it is 0, it means our bot takes a lot of damage\n",
    "#                                         if it is 10, it means our bot gives a lot of damage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_save(data, file_name):\n",
    "    p1_hp_normalizer = Normalizer()\n",
    "    p1_normalized_hp = p1_hp_normalizer.normalize(data)\n",
    "    p1_hp_normalizer.save(OUT_FOLDER + '/' + file_name)\n",
    "    return p1_normalized_hp\n",
    "\n",
    "def process_data(game_data_obj):\n",
    "    ## Pre process data\n",
    "    processed_data = []\n",
    "    frames = [frame for frame in game_data_obj]\n",
    "    actions = []\n",
    "    p1x = []\n",
    "    p1y = []\n",
    "    p2x = []\n",
    "    p2y = []\n",
    "    hpdifs = []\n",
    "\n",
    "    for i in range(0,len(frames)-1,2):\n",
    "        actions.append(frames[i]['P1-action'])\n",
    "        p1x.append(frames[i]['P1-x'])\n",
    "        p1y.append(frames[i]['P1-y'])\n",
    "        p2x.append(frames[i]['P2-x'])\n",
    "        p2y.append(frames[i]['P2-y'])\n",
    "        after = (frames[i+1]['P2-hp'] - frames[i+1]['P1-hp'])\n",
    "        before = (frames[i]['P2-hp'] - frames[i]['P1-hp'])\n",
    "        last = int(after - before) // 10\n",
    "        if last < -5:\n",
    "            last = -5\n",
    "        if last > 5:\n",
    "            last = 5\n",
    "#       print(\"ust: \" + str(ust) + \", alt: \" + str(alt) + \", res: \" + str(a))\n",
    "        hpdifs.append(last)\n",
    "    \n",
    "    # Create one hot encoding for actions (For input and labels)\n",
    "    p1_one_hot_encoded_actions = one_hot_encode(actions)\n",
    "    labels = one_hot_encode_hpdif(hpdifs)\n",
    "\n",
    "    # Normalize uncategorized features\n",
    "    normalized_xp1_distance = normalize_and_save(p1x, \"xp1_norm.save\")\n",
    "    normalized_xp2_distance = normalize_and_save(p2x, \"xp2_norm.save\")\n",
    "    normalized_yp1_distance = normalize_and_save(p1y, \"yp1_norm.save\")\n",
    "    normalized_yp2_distance = normalize_and_save(p2y, \"yp2_norm.save\")\n",
    "\n",
    "    for index in range(len(p1_one_hot_encoded_actions)):    \n",
    "        processed_row = []\n",
    "        processed_row.extend(p1_one_hot_encoded_actions[index])\n",
    "        processed_row.extend(normalized_xp1_distance[index])\n",
    "        processed_row.extend(normalized_xp2_distance[index])\n",
    "        processed_row.extend(normalized_yp1_distance[index])\n",
    "        processed_row.extend(normalized_yp2_distance[index])\n",
    "        processed_data.append(processed_row)\n",
    "    processed_data = np.array(processed_data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return processed_data, labels\n",
    "\n",
    "tr_data, tr_labels = process_data(training_data)\n",
    "te_data, te_labels = process_data(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 0 0]\n",
      "There are 3058 frames in dataset.\n",
      "After pre processing the shape of our dataset is (3058, 59)\n",
      "\n",
      "One example in index 10.\n",
      "\tProcessed Frame:\n",
      "\t\tP1 Action(one-hot) Shape:\t[1, 54]\n",
      "\t\tP1 Hp(norm.):\t\t\t0.7375\n",
      "\t\tP2 Hp(norm.):\t\t\t0.6425\n",
      "\t\tX Dist(norm.):\t\t\t0.9999999999999999\n",
      "\t\tY Dist(norm.):\t\t\t1.0\n",
      "\t\tLabel Shape:\t\t\t[1, 11]\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_ROW = 10\n",
    "print(tr_labels[6])\n",
    "print(\"There are %d frames in dataset.\" % len(tr_data))\n",
    "print(\"After pre processing the shape of our dataset is %s\" % str(tr_data.shape))\n",
    "print(\"\\nOne example in index %d.\" % EXAMPLE_ROW)\n",
    "\n",
    "row = tr_data[EXAMPLE_ROW]\n",
    "print(\"\\tProcessed Frame:\" )\n",
    "print(\"\\t\\tP1 Action(one-hot) Shape:\\t[1, %d]\" % 54)\n",
    "print(\"\\t\\tP1 Hp(norm.):\\t\\t\\t%s\" % row[55])\n",
    "print(\"\\t\\tP2 Hp(norm.):\\t\\t\\t%s\" % row[56])\n",
    "print(\"\\t\\tX Dist(norm.):\\t\\t\\t%s\" % row[57])\n",
    "print(\"\\t\\tY Dist(norm.):\\t\\t\\t%s\" % row[58])\n",
    "print(\"\\t\\tLabel Shape:\\t\\t\\t[1, %d]\" % len(tr_labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Design\n",
    "\n",
    "Our neural network has two hidden layers in this test. They has 12 and 8 neurons respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "INPUT_LAYER_SIZE = tr_data.shape[1]\n",
    "OUTPUT_LAYER_SIZE = tr_labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neuron_count):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(neuron_count, input_dim=INPUT_LAYER_SIZE, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(OUTPUT_LAYER_SIZE, activation='softmax'))\n",
    "    print( OUTPUT_LAYER_SIZE )\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLEXITIES = [256]\n",
    "EPOCH = 100\n",
    "BATCH = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Model created with 256 neurons.\n",
      "\tTraining started.\n",
      "Train on 2446 samples, validate on 612 samples\n",
      "Epoch 1/100\n",
      "2446/2446 [==============================] - 1s 253us/step - loss: 0.8175 - acc: 0.7796 - val_loss: 0.4894 - val_acc: 0.8284\n",
      "Epoch 2/100\n",
      "2446/2446 [==============================] - 0s 192us/step - loss: 0.5318 - acc: 0.8050 - val_loss: 0.4474 - val_acc: 0.8399\n",
      "Epoch 3/100\n",
      "2446/2446 [==============================] - 0s 165us/step - loss: 0.5060 - acc: 0.8148 - val_loss: 0.4608 - val_acc: 0.8448\n",
      "Epoch 4/100\n",
      "2446/2446 [==============================] - 0s 199us/step - loss: 0.4908 - acc: 0.8201 - val_loss: 0.4320 - val_acc: 0.8448\n",
      "Epoch 5/100\n",
      "2446/2446 [==============================] - 0s 130us/step - loss: 0.4791 - acc: 0.8189 - val_loss: 0.4598 - val_acc: 0.8415\n",
      "Epoch 6/100\n",
      "2446/2446 [==============================] - 0s 138us/step - loss: 0.4796 - acc: 0.8164 - val_loss: 0.4355 - val_acc: 0.8448\n",
      "Epoch 7/100\n",
      "2446/2446 [==============================] - 0s 174us/step - loss: 0.4728 - acc: 0.8201 - val_loss: 0.4444 - val_acc: 0.8448\n",
      "Epoch 8/100\n",
      "2446/2446 [==============================] - 0s 130us/step - loss: 0.4775 - acc: 0.8181 - val_loss: 0.4379 - val_acc: 0.8415\n",
      "Epoch 9/100\n",
      "2446/2446 [==============================] - 0s 162us/step - loss: 0.4739 - acc: 0.8168 - val_loss: 0.4308 - val_acc: 0.8448\n",
      "Epoch 10/100\n",
      "2446/2446 [==============================] - 0s 134us/step - loss: 0.4682 - acc: 0.8246 - val_loss: 0.4330 - val_acc: 0.8448\n",
      "Epoch 11/100\n",
      "2446/2446 [==============================] - 0s 175us/step - loss: 0.4634 - acc: 0.8238 - val_loss: 0.4332 - val_acc: 0.8431\n",
      "Epoch 12/100\n",
      "2446/2446 [==============================] - 0s 185us/step - loss: 0.4641 - acc: 0.8201 - val_loss: 0.4391 - val_acc: 0.8448\n",
      "Epoch 13/100\n",
      "2446/2446 [==============================] - 0s 188us/step - loss: 0.4633 - acc: 0.8250 - val_loss: 0.4507 - val_acc: 0.8448\n",
      "Epoch 14/100\n",
      "2446/2446 [==============================] - 0s 183us/step - loss: 0.4627 - acc: 0.8189 - val_loss: 0.4358 - val_acc: 0.8415\n",
      "Epoch 15/100\n",
      "2446/2446 [==============================] - 0s 152us/step - loss: 0.4582 - acc: 0.8213 - val_loss: 0.4416 - val_acc: 0.8448\n",
      "Epoch 16/100\n",
      "2446/2446 [==============================] - 0s 164us/step - loss: 0.4564 - acc: 0.8238 - val_loss: 0.4476 - val_acc: 0.8448\n",
      "Epoch 17/100\n",
      "2446/2446 [==============================] - 0s 192us/step - loss: 0.4590 - acc: 0.8222 - val_loss: 0.4430 - val_acc: 0.8562\n",
      "Epoch 18/100\n",
      "2446/2446 [==============================] - 0s 169us/step - loss: 0.4581 - acc: 0.8262 - val_loss: 0.4455 - val_acc: 0.8448\n",
      "Epoch 19/100\n",
      "2446/2446 [==============================] - 0s 149us/step - loss: 0.4591 - acc: 0.8222 - val_loss: 0.4554 - val_acc: 0.8431\n",
      "Epoch 20/100\n",
      "2446/2446 [==============================] - 0s 150us/step - loss: 0.4564 - acc: 0.8185 - val_loss: 0.4532 - val_acc: 0.8497\n",
      "Epoch 21/100\n",
      "2446/2446 [==============================] - 0s 175us/step - loss: 0.4517 - acc: 0.8275 - val_loss: 0.4384 - val_acc: 0.8415\n",
      "Epoch 22/100\n",
      "2446/2446 [==============================] - 0s 154us/step - loss: 0.4488 - acc: 0.8238 - val_loss: 0.4469 - val_acc: 0.8366\n",
      "Epoch 23/100\n",
      "2446/2446 [==============================] - 0s 159us/step - loss: 0.4501 - acc: 0.8234 - val_loss: 0.4375 - val_acc: 0.8448\n",
      "Epoch 24/100\n",
      "2446/2446 [==============================] - 0s 152us/step - loss: 0.4478 - acc: 0.8234 - val_loss: 0.4375 - val_acc: 0.8431\n",
      "Epoch 25/100\n",
      "2446/2446 [==============================] - 0s 157us/step - loss: 0.4474 - acc: 0.8226 - val_loss: 0.4387 - val_acc: 0.8448\n",
      "Epoch 26/100\n",
      "2446/2446 [==============================] - 1s 209us/step - loss: 0.4448 - acc: 0.8275 - val_loss: 0.4632 - val_acc: 0.8529\n",
      "Epoch 27/100\n",
      "2446/2446 [==============================] - 0s 161us/step - loss: 0.4406 - acc: 0.8328 - val_loss: 0.4625 - val_acc: 0.8480\n",
      "Epoch 28/100\n",
      "2446/2446 [==============================] - 0s 152us/step - loss: 0.4404 - acc: 0.8287 - val_loss: 0.4398 - val_acc: 0.8497\n",
      "Epoch 29/100\n",
      "2446/2446 [==============================] - 0s 145us/step - loss: 0.4413 - acc: 0.8262 - val_loss: 0.4555 - val_acc: 0.8480\n",
      "Epoch 30/100\n",
      "2446/2446 [==============================] - 0s 199us/step - loss: 0.4376 - acc: 0.8312 - val_loss: 0.4509 - val_acc: 0.8497\n",
      "Epoch 31/100\n",
      "2446/2446 [==============================] - 0s 169us/step - loss: 0.4370 - acc: 0.8328 - val_loss: 0.4498 - val_acc: 0.8480\n",
      "Epoch 32/100\n",
      "2446/2446 [==============================] - 0s 165us/step - loss: 0.4368 - acc: 0.8328 - val_loss: 0.4459 - val_acc: 0.8595\n",
      "Epoch 33/100\n",
      "2446/2446 [==============================] - 0s 159us/step - loss: 0.4376 - acc: 0.8303 - val_loss: 0.4577 - val_acc: 0.8448\n",
      "Epoch 34/100\n",
      "2446/2446 [==============================] - 0s 148us/step - loss: 0.4315 - acc: 0.8299 - val_loss: 0.4470 - val_acc: 0.8644\n",
      "Epoch 35/100\n",
      "2446/2446 [==============================] - 1s 240us/step - loss: 0.4317 - acc: 0.8393 - val_loss: 0.4557 - val_acc: 0.8611\n",
      "Epoch 36/100\n",
      "2446/2446 [==============================] - 1s 205us/step - loss: 0.4310 - acc: 0.8434 - val_loss: 0.4497 - val_acc: 0.8611\n",
      "Epoch 37/100\n",
      "2446/2446 [==============================] - 0s 167us/step - loss: 0.4322 - acc: 0.8348 - val_loss: 0.4605 - val_acc: 0.8513\n",
      "Epoch 38/100\n",
      "2446/2446 [==============================] - 0s 156us/step - loss: 0.4304 - acc: 0.8381 - val_loss: 0.4538 - val_acc: 0.8562\n",
      "Epoch 39/100\n",
      "2446/2446 [==============================] - 0s 162us/step - loss: 0.4258 - acc: 0.8385 - val_loss: 0.4662 - val_acc: 0.8562\n",
      "Epoch 40/100\n",
      "2446/2446 [==============================] - 0s 188us/step - loss: 0.4297 - acc: 0.8352 - val_loss: 0.4432 - val_acc: 0.8627\n",
      "Epoch 41/100\n",
      "2446/2446 [==============================] - 0s 160us/step - loss: 0.4210 - acc: 0.8422 - val_loss: 0.4507 - val_acc: 0.8676\n",
      "Epoch 42/100\n",
      "2446/2446 [==============================] - 0s 162us/step - loss: 0.4234 - acc: 0.8348 - val_loss: 0.4513 - val_acc: 0.8660\n",
      "Epoch 43/100\n",
      "2446/2446 [==============================] - 0s 165us/step - loss: 0.4206 - acc: 0.8414 - val_loss: 0.4660 - val_acc: 0.8611\n",
      "Epoch 44/100\n",
      "2446/2446 [==============================] - 0s 155us/step - loss: 0.4171 - acc: 0.8434 - val_loss: 0.4484 - val_acc: 0.8546\n",
      "Epoch 45/100\n",
      "2446/2446 [==============================] - 0s 163us/step - loss: 0.4144 - acc: 0.8491 - val_loss: 0.4504 - val_acc: 0.8595\n",
      "Epoch 46/100\n",
      "2446/2446 [==============================] - 0s 165us/step - loss: 0.4194 - acc: 0.8471 - val_loss: 0.4428 - val_acc: 0.8725\n",
      "Epoch 47/100\n",
      "2446/2446 [==============================] - 0s 157us/step - loss: 0.4096 - acc: 0.8512 - val_loss: 0.4473 - val_acc: 0.8611\n",
      "Epoch 48/100\n",
      "2446/2446 [==============================] - 0s 148us/step - loss: 0.4107 - acc: 0.8467 - val_loss: 0.4622 - val_acc: 0.8464\n",
      "Epoch 49/100\n",
      "2446/2446 [==============================] - 0s 181us/step - loss: 0.4091 - acc: 0.8434 - val_loss: 0.4781 - val_acc: 0.8448\n",
      "Epoch 50/100\n",
      "2446/2446 [==============================] - 0s 183us/step - loss: 0.4079 - acc: 0.8512 - val_loss: 0.4501 - val_acc: 0.8742\n",
      "Epoch 51/100\n",
      "2446/2446 [==============================] - 0s 203us/step - loss: 0.4020 - acc: 0.8520 - val_loss: 0.4532 - val_acc: 0.8725\n",
      "Epoch 52/100\n",
      "2446/2446 [==============================] - 0s 201us/step - loss: 0.4036 - acc: 0.8536 - val_loss: 0.4402 - val_acc: 0.8742\n",
      "Epoch 53/100\n",
      "2446/2446 [==============================] - 0s 170us/step - loss: 0.3979 - acc: 0.8520 - val_loss: 0.4523 - val_acc: 0.8709\n",
      "Epoch 54/100\n",
      "2446/2446 [==============================] - 0s 191us/step - loss: 0.3937 - acc: 0.8581 - val_loss: 0.4518 - val_acc: 0.8758\n",
      "Epoch 55/100\n",
      "2446/2446 [==============================] - 0s 175us/step - loss: 0.3926 - acc: 0.8573 - val_loss: 0.4526 - val_acc: 0.8676\n",
      "Epoch 56/100\n",
      "2446/2446 [==============================] - 0s 174us/step - loss: 0.3929 - acc: 0.8540 - val_loss: 0.4440 - val_acc: 0.8775\n",
      "Epoch 57/100\n",
      "2446/2446 [==============================] - 0s 176us/step - loss: 0.3868 - acc: 0.8581 - val_loss: 0.4714 - val_acc: 0.8464\n",
      "Epoch 58/100\n",
      "2446/2446 [==============================] - 0s 175us/step - loss: 0.3775 - acc: 0.8606 - val_loss: 0.4560 - val_acc: 0.8676\n",
      "Epoch 59/100\n",
      "2446/2446 [==============================] - 0s 166us/step - loss: 0.3735 - acc: 0.8630 - val_loss: 0.4829 - val_acc: 0.8497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "2446/2446 [==============================] - 0s 152us/step - loss: 0.3768 - acc: 0.8516 - val_loss: 0.4320 - val_acc: 0.8840\n",
      "Epoch 61/100\n",
      "2446/2446 [==============================] - 0s 163us/step - loss: 0.3640 - acc: 0.8618 - val_loss: 0.4336 - val_acc: 0.8824\n",
      "Epoch 62/100\n",
      "2446/2446 [==============================] - 0s 174us/step - loss: 0.3574 - acc: 0.8659 - val_loss: 0.4541 - val_acc: 0.8693\n",
      "Epoch 63/100\n",
      "2446/2446 [==============================] - 0s 171us/step - loss: 0.3557 - acc: 0.8724 - val_loss: 0.4251 - val_acc: 0.8824\n",
      "Epoch 64/100\n",
      "2446/2446 [==============================] - 0s 172us/step - loss: 0.3576 - acc: 0.8659 - val_loss: 0.4342 - val_acc: 0.8824\n",
      "Epoch 65/100\n",
      "2446/2446 [==============================] - 0s 174us/step - loss: 0.3418 - acc: 0.8790 - val_loss: 0.4599 - val_acc: 0.8742\n",
      "Epoch 66/100\n",
      "2446/2446 [==============================] - 0s 160us/step - loss: 0.3370 - acc: 0.8790 - val_loss: 0.4506 - val_acc: 0.8873\n",
      "Epoch 67/100\n",
      "2446/2446 [==============================] - 0s 155us/step - loss: 0.3395 - acc: 0.8757 - val_loss: 0.4372 - val_acc: 0.8856\n",
      "Epoch 68/100\n",
      "2446/2446 [==============================] - 0s 152us/step - loss: 0.3346 - acc: 0.8733 - val_loss: 0.4396 - val_acc: 0.8824\n",
      "Epoch 69/100\n",
      "2446/2446 [==============================] - 0s 150us/step - loss: 0.3292 - acc: 0.8798 - val_loss: 0.4338 - val_acc: 0.8873\n",
      "Epoch 70/100\n",
      "2446/2446 [==============================] - 0s 148us/step - loss: 0.3253 - acc: 0.8835 - val_loss: 0.4210 - val_acc: 0.8840\n",
      "Epoch 71/100\n",
      "2446/2446 [==============================] - 0s 152us/step - loss: 0.3234 - acc: 0.8851 - val_loss: 0.4407 - val_acc: 0.8807\n",
      "Epoch 72/100\n",
      "2446/2446 [==============================] - 0s 153us/step - loss: 0.3346 - acc: 0.8720 - val_loss: 0.4274 - val_acc: 0.8758\n",
      "Epoch 73/100\n",
      "2446/2446 [==============================] - 0s 164us/step - loss: 0.3142 - acc: 0.8835 - val_loss: 0.4261 - val_acc: 0.8824\n",
      "Epoch 74/100\n",
      "2446/2446 [==============================] - 0s 163us/step - loss: 0.3172 - acc: 0.8839 - val_loss: 0.4661 - val_acc: 0.8611\n",
      "Epoch 75/100\n",
      "2446/2446 [==============================] - 0s 161us/step - loss: 0.3108 - acc: 0.8908 - val_loss: 0.4203 - val_acc: 0.8873\n",
      "Epoch 76/100\n",
      "2446/2446 [==============================] - 0s 166us/step - loss: 0.3060 - acc: 0.8880 - val_loss: 0.4339 - val_acc: 0.8840\n",
      "Epoch 77/100\n",
      "2446/2446 [==============================] - 0s 147us/step - loss: 0.3119 - acc: 0.8839 - val_loss: 0.4499 - val_acc: 0.8660\n",
      "Epoch 78/100\n",
      "2446/2446 [==============================] - 0s 170us/step - loss: 0.3067 - acc: 0.8806 - val_loss: 0.4380 - val_acc: 0.8775\n",
      "Epoch 79/100\n",
      "2446/2446 [==============================] - 0s 153us/step - loss: 0.3048 - acc: 0.8855 - val_loss: 0.4302 - val_acc: 0.8840\n",
      "Epoch 80/100\n",
      "2446/2446 [==============================] - 0s 158us/step - loss: 0.3053 - acc: 0.8892 - val_loss: 0.4295 - val_acc: 0.8905\n",
      "Epoch 81/100\n",
      "2446/2446 [==============================] - 0s 159us/step - loss: 0.3021 - acc: 0.8941 - val_loss: 0.4513 - val_acc: 0.8709\n",
      "Epoch 82/100\n",
      "2446/2446 [==============================] - 0s 147us/step - loss: 0.3011 - acc: 0.8851 - val_loss: 0.4268 - val_acc: 0.8840\n",
      "Epoch 83/100\n",
      "2446/2446 [==============================] - 0s 175us/step - loss: 0.2974 - acc: 0.8876 - val_loss: 0.4489 - val_acc: 0.8595\n",
      "Epoch 84/100\n",
      "2446/2446 [==============================] - 1s 232us/step - loss: 0.3034 - acc: 0.8876 - val_loss: 0.4194 - val_acc: 0.8922\n",
      "Epoch 85/100\n",
      "2446/2446 [==============================] - 0s 145us/step - loss: 0.3010 - acc: 0.8913 - val_loss: 0.4309 - val_acc: 0.8889\n",
      "Epoch 86/100\n",
      "2446/2446 [==============================] - 0s 157us/step - loss: 0.3045 - acc: 0.8876 - val_loss: 0.4320 - val_acc: 0.8791\n",
      "Epoch 87/100\n",
      "2446/2446 [==============================] - 0s 154us/step - loss: 0.2945 - acc: 0.8904 - val_loss: 0.4372 - val_acc: 0.8693\n",
      "Epoch 88/100\n",
      "2446/2446 [==============================] - 0s 154us/step - loss: 0.2908 - acc: 0.8917 - val_loss: 0.4469 - val_acc: 0.8693\n",
      "Epoch 89/100\n",
      "2446/2446 [==============================] - 0s 160us/step - loss: 0.2877 - acc: 0.8904 - val_loss: 0.4313 - val_acc: 0.8840\n",
      "Epoch 90/100\n",
      "2446/2446 [==============================] - 0s 157us/step - loss: 0.2951 - acc: 0.8904 - val_loss: 0.4232 - val_acc: 0.8856\n",
      "Epoch 91/100\n",
      "2446/2446 [==============================] - 0s 165us/step - loss: 0.3002 - acc: 0.8913 - val_loss: 0.4969 - val_acc: 0.8611\n",
      "Epoch 92/100\n",
      "2446/2446 [==============================] - 0s 143us/step - loss: 0.2896 - acc: 0.8913 - val_loss: 0.4302 - val_acc: 0.8905\n",
      "Epoch 93/100\n",
      "2446/2446 [==============================] - 0s 150us/step - loss: 0.2819 - acc: 0.8945 - val_loss: 0.4602 - val_acc: 0.8775\n",
      "Epoch 94/100\n",
      "2446/2446 [==============================] - 0s 146us/step - loss: 0.2970 - acc: 0.8941 - val_loss: 0.4299 - val_acc: 0.8824\n",
      "Epoch 95/100\n",
      "2446/2446 [==============================] - 0s 153us/step - loss: 0.2857 - acc: 0.8904 - val_loss: 0.4526 - val_acc: 0.8742\n",
      "Epoch 96/100\n",
      "2446/2446 [==============================] - 0s 170us/step - loss: 0.2854 - acc: 0.8880 - val_loss: 0.4302 - val_acc: 0.8807\n",
      "Epoch 97/100\n",
      "2446/2446 [==============================] - 0s 192us/step - loss: 0.2960 - acc: 0.8904 - val_loss: 0.4498 - val_acc: 0.8791\n",
      "Epoch 98/100\n",
      "2446/2446 [==============================] - 0s 191us/step - loss: 0.2910 - acc: 0.8888 - val_loss: 0.4399 - val_acc: 0.8840\n",
      "Epoch 99/100\n",
      "2446/2446 [==============================] - 0s 167us/step - loss: 0.2870 - acc: 0.8966 - val_loss: 0.4431 - val_acc: 0.8873\n",
      "Epoch 100/100\n",
      "2446/2446 [==============================] - 0s 169us/step - loss: 0.2820 - acc: 0.8929 - val_loss: 0.4313 - val_acc: 0.8791\n",
      "\tTraining ended.\n",
      "974/974 [==============================] - 0s 26us/step\n",
      "\t\n",
      "acc: 84.50%\n",
      "Session completed successfully. 1 networks created and their data saved.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(OUT_FOLDER):\n",
    "    os.makedirs(OUT_FOLDER)\n",
    "\n",
    "name = \"nof1\"\n",
    "# Create session folder.\n",
    "SESSION_FOLDER = OUT_FOLDER + '/session_{}{}'.format(time.time(),name)\n",
    "\n",
    "os.makedirs(SESSION_FOLDER)\n",
    "os.makedirs(SESSION_FOLDER + '/models')\n",
    "os.makedirs(SESSION_FOLDER + '/logs')\n",
    "os.makedirs(SESSION_FOLDER + '/histories')\n",
    "\n",
    "histories = []\n",
    "# Create and run networks\n",
    "for complexity in COMPLEXITIES:\n",
    "    starting_time = time.clock()\n",
    "    file_name = str(complexity)\n",
    "    model = create_model(complexity)\n",
    "    print('Model created with {} neurons.'.format(complexity))\n",
    "    \n",
    "    # Logging for tensorboard\n",
    "    tensorboard = TensorBoard(log_dir= SESSION_FOLDER + \"/logs/log_{}\".format(file_name))\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    print('\\tTraining started.')\n",
    "    checkpoint = ModelCheckpoint(filepath=\"model.h5\", save_best_only=True, verbose=0)\n",
    "    history = model.fit(tr_data, tr_labels, validation_split=0.2, epochs=EPOCH,\n",
    "                    shuffle=True, batch_size=BATCH, callbacks=[tensorboard,checkpoint])\n",
    "    print('\\tTraining ended.')\n",
    "    \n",
    "    model.load_weights(\"model.h5\")\n",
    "    time_taken = time.clock() - starting_time * 1000.0\n",
    "    \n",
    "    model_info = {\n",
    "        'info': 'One hidden layer ANN with {} neurons'.format(complexity),\n",
    "        'epoch': EPOCH,\n",
    "        'batch': BATCH,\n",
    "        'time_taken': time_taken\n",
    "    }\n",
    "    \n",
    "    # Save model and history\n",
    "    model.save(SESSION_FOLDER + '/models/model_{}.h5'.format(file_name))\n",
    "    write_file(SESSION_FOLDER + '/models/config_{}.json'.format(file_name), model.to_json())\n",
    "    write_file(SESSION_FOLDER + '/models/info_{}.json'.format(file_name), json.dumps(model_info))\n",
    "    model.save(OUT_FOLDER + '/model.h5'.format(file_name))\n",
    "    write_file(OUT_FOLDER + '/config.json'.format(file_name), model.to_json())\n",
    "    write_file(OUT_FOLDER + '/info.json'.format(file_name), json.dumps(model_info))\n",
    "    \n",
    "    # Display result\n",
    "    scores = model.evaluate(te_data, te_labels)\n",
    "    print(\"\\t\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    pickle.dump(history, open(SESSION_FOLDER + '/histories/history_{}.save'.format(file_name), 'wb'))\n",
    "    \n",
    "    histories.append(history)\n",
    "    \n",
    "    \n",
    "print('Session completed successfully. {} networks created and their data saved.'.format(len(COMPLEXITIES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974/974 [==============================] - 0s 27us/step\n",
      "\t\n",
      "acc: 84.50%\n",
      "[0.5181070648791609, 0.8449691991786448]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display result\n",
    "scores = model.evaluate(te_data, te_labels)\n",
    "print(\"\\t\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testing_data2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-92026122b5cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mte_data2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_labels2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_data2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte_data2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_labels2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\\n%s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testing_data2' is not defined"
     ]
    }
   ],
   "source": [
    "# te_data2, te_labels2 = process_data(testing_data2)\n",
    "# scores = model.evaluate(te_data2, te_labels2)\n",
    "# print(\"\\t\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "# print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
