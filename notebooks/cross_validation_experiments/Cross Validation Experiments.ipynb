{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook includes the experiments for cross validation.\n",
    "\n",
    "- Standing agent is P1, we are learning P2 (P2 is human player).\n",
    "\n",
    "- Some frames will be removed, there are frames that;\n",
    "    - Both players standing.\n",
    "    - Consecutive ones(If frame's action is same with previous frame, it will be removed).\n",
    "    - If we are(P2) in RECOV frame(Since we don't make RECOV frames ourselves)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For using core package that located in the two upper folder.\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from core.json_importer import parse_json_file, parse_all_files\n",
    "from core.filters import remove_both_standing_frames, remove_same_consecutive_actions, remove_recov_frames\n",
    "from core.actions import one_hot_encode, decode\n",
    "from core.preproccessing import Normalizer\n",
    "from core.helpers import write_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open files\n",
    "training_data = parse_all_files(\"data/train\")\n",
    "testing_data = parse_all_files(\"data/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre process data\n",
    "\n",
    "- In the pre process phase, we remove P2's datas from training set in order to crate labels. Labels are just actions of P2.\n",
    "\n",
    "- We make actions one-hot encoding. \n",
    "\n",
    "- One-hot encoding for inputs and labels are not same. For example, Dash action in the input may have encoding [0,1] while Dash action in the label have encoding [0, 0, 1, 0].\n",
    "\n",
    "- Integer values normalized. (P1-HP, P2-HP, P1-X, P1-Y, P2-X, P2-Y)\n",
    "\n",
    "- After pre-process we just have <font color='red'>[P1-Action, P1-HP, P2-HP, P1-X, P1-Y, P2-X, P2-Y] -> P2-Action</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove unneeded frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11428 train data.(485372 deleted.)\n",
      "There are 1221 test data.(52779 deleted.)\n"
     ]
    }
   ],
   "source": [
    "# Apply filters for training data\n",
    "tr_deleted = training_data.filter(remove_both_standing_frames)\n",
    "tr_deleted += training_data.filter(remove_recov_frames)\n",
    "tr_deleted += training_data.filter(remove_same_consecutive_actions)\n",
    "\n",
    "# Apply filters for training data\n",
    "te_deleted = testing_data.filter(remove_both_standing_frames)\n",
    "te_deleted += testing_data.filter(remove_recov_frames)\n",
    "te_deleted += testing_data.filter(remove_same_consecutive_actions)\n",
    "\n",
    "print('There are {} train data.({} deleted.)'.format(len(training_data), tr_deleted))\n",
    "print('There are {} test data.({} deleted.)'.format(len(testing_data), te_deleted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_save(data, file_name):\n",
    "    p1_hp_normalizer = Normalizer()\n",
    "    p1_normalized_hp = p1_hp_normalizer.normalize(data)\n",
    "    p1_hp_normalizer.save(\"out_files/\" + file_name)\n",
    "    return p1_normalized_hp\n",
    "\n",
    "def process_data(game_data_obj):\n",
    "    ## Pre process data\n",
    "    processed_data = []\n",
    "\n",
    "    # Create one hot encoding for actions (For input and labels)\n",
    "    p1_one_hot_encoded_actions = one_hot_encode(game_data_obj.get_column(\"P1-action\"))\n",
    "    labels = one_hot_encode(game_data_obj.get_column(\"P2-action\"))\n",
    "\n",
    "    # Normalize uncategorized features\n",
    "    p1_normalized_hp = normalize_and_save(game_data_obj.get_column(\"P1-hp\"), \"p1_hp_norm.save\")\n",
    "    p2_normalized_hp = normalize_and_save(game_data_obj.get_column(\"P2-hp\"), \"p2_hp_norm.save\")\n",
    "    normalized_x_distance = normalize_and_save([frame[\"P1-x\"] - frame[\"P2-x\"] for frame in game_data_obj], \"x_norm.save\")\n",
    "    normalized_y_distance = normalize_and_save([frame[\"P1-y\"] - frame[\"P2-y\"] for frame in game_data_obj], \"y_norm.save\")\n",
    "    normalized_xp1_distance = normalize_and_save([frame[\"P1-x\"] for frame in game_data_obj], \"xp1_norm.save\")\n",
    "    normalized_xp2_distance = normalize_and_save([frame[\"P2-x\"] for frame in game_data_obj], \"xp2_norm.save\")\n",
    "    normalized_yp1_distance = normalize_and_save([frame[\"P1-y\"] for frame in game_data_obj], \"yp1_norm.save\")\n",
    "    normalized_yp2_distance = normalize_and_save([frame[\"P2-y\"] for frame in game_data_obj], \"yp2_norm.save\")\n",
    "\n",
    "    for index in range(len(game_data_obj)):    \n",
    "        processed_row = []\n",
    "        processed_row.extend(p1_one_hot_encoded_actions[index])\n",
    "        processed_row.extend(p1_normalized_hp[index]) \n",
    "        processed_row.extend(p2_normalized_hp[index])\n",
    "        processed_row.extend(normalized_x_distance[index])\n",
    "        processed_row.extend(normalized_y_distance[index])\n",
    "        processed_row.extend(normalized_xp1_distance[index])\n",
    "        processed_row.extend(normalized_xp2_distance[index])\n",
    "        processed_row.extend(normalized_yp1_distance[index])\n",
    "        processed_row.extend(normalized_yp2_distance[index])\n",
    "        processed_data.append(processed_row)\n",
    "    processed_data = np.array(processed_data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return processed_data, labels\n",
    "    \n",
    "tr_data, tr_labels = process_data(training_data)\n",
    "te_data, te_labels = process_data(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11428 frames in dataset.\n",
      "After pre processing the shape of our dataset is (11428, 63)\n",
      "\n",
      "One example in index 10.\n",
      "\tProcessed Frame:\n",
      "\t\tP1 Action(one-hot):\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.]\n",
      "\t\tP1 Hp(norm.):\t\t0.01594896331738437\n",
      "\t\tP2 Hp(norm.):\t\t0.010683760683760684\n",
      "\t\tX Dist(norm.):\t\t0.04660452729693742\n",
      "\t\tY Dist(norm.):\t\t0.4398034398034398\n",
      "\t\tLabel:\t\t\t[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_ROW = 10\n",
    "\n",
    "print(\"There are %d frames in dataset.\" % len(tr_data))\n",
    "print(\"After pre processing the shape of our dataset is %s\" % str(tr_data.shape))\n",
    "print(\"\\nOne example in index %d.\" % EXAMPLE_ROW)\n",
    "\n",
    "row = tr_data[EXAMPLE_ROW]\n",
    "print(\"\\tProcessed Frame:\" )\n",
    "print(\"\\t\\tP1 Action(one-hot):\\t%s\" % row[0: 55])\n",
    "print(\"\\t\\tP1 Hp(norm.):\\t\\t%s\" % row[55])\n",
    "print(\"\\t\\tP2 Hp(norm.):\\t\\t%s\" % row[56])\n",
    "print(\"\\t\\tX Dist(norm.):\\t\\t%s\" % row[57])\n",
    "print(\"\\t\\tY Dist(norm.):\\t\\t%s\" % row[58])\n",
    "print(\"\\t\\tLabel:\\t\\t\\t%s\" % tr_labels[EXAMPLE_ROW])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Design\n",
    "\n",
    "Our neural network has two hidden layers in this test. They has 12 and 8 neurons respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "INPUT_LAYER_SIZE = tr_data.shape[1]\n",
    "OUTPUT_LAYER_SIZE = tr_labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=INPUT_LAYER_SIZE, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(OUTPUT_LAYER_SIZE, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging for tensorboard\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9142 samples, validate on 2286 samples\n",
      "Epoch 1/500\n",
      "9142/9142 [==============================] - 2s 239us/step - loss: 0.1001 - acc: 0.9750 - val_loss: 0.0597 - val_acc: 0.9823\n",
      "Epoch 2/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0590 - acc: 0.9825 - val_loss: 0.0553 - val_acc: 0.9828\n",
      "Epoch 3/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0558 - acc: 0.9831 - val_loss: 0.0534 - val_acc: 0.9833\n",
      "Epoch 4/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0541 - acc: 0.9832 - val_loss: 0.0521 - val_acc: 0.9837\n",
      "Epoch 5/500\n",
      "9142/9142 [==============================] - 2s 199us/step - loss: 0.0529 - acc: 0.9834 - val_loss: 0.0515 - val_acc: 0.9837\n",
      "Epoch 6/500\n",
      "9142/9142 [==============================] - 2s 210us/step - loss: 0.0522 - acc: 0.9835 - val_loss: 0.0509 - val_acc: 0.9838\n",
      "Epoch 7/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0515 - acc: 0.9837 - val_loss: 0.0504 - val_acc: 0.9838\n",
      "Epoch 8/500\n",
      "9142/9142 [==============================] - 2s 204us/step - loss: 0.0509 - acc: 0.9837 - val_loss: 0.0501 - val_acc: 0.9838\n",
      "Epoch 9/500\n",
      "9142/9142 [==============================] - 2s 217us/step - loss: 0.0503 - acc: 0.9839 - val_loss: 0.0495 - val_acc: 0.9839\n",
      "Epoch 10/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0499 - acc: 0.9839 - val_loss: 0.0492 - val_acc: 0.9839\n",
      "Epoch 11/500\n",
      "9142/9142 [==============================] - 2s 200us/step - loss: 0.0494 - acc: 0.9840 - val_loss: 0.0488 - val_acc: 0.9841\n",
      "Epoch 12/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0491 - acc: 0.9842 - val_loss: 0.0484 - val_acc: 0.9841\n",
      "Epoch 13/500\n",
      "9142/9142 [==============================] - 2s 202us/step - loss: 0.0486 - acc: 0.9842 - val_loss: 0.0481 - val_acc: 0.9841\n",
      "Epoch 14/500\n",
      "9142/9142 [==============================] - 2s 200us/step - loss: 0.0483 - acc: 0.9843 - val_loss: 0.0477 - val_acc: 0.9843\n",
      "Epoch 15/500\n",
      "9142/9142 [==============================] - 2s 217us/step - loss: 0.0481 - acc: 0.9843 - val_loss: 0.0474 - val_acc: 0.9844\n",
      "Epoch 16/500\n",
      "9142/9142 [==============================] - 2s 211us/step - loss: 0.0477 - acc: 0.9843 - val_loss: 0.0473 - val_acc: 0.9843\n",
      "Epoch 17/500\n",
      "9142/9142 [==============================] - 2s 215us/step - loss: 0.0473 - acc: 0.9845 - val_loss: 0.0469 - val_acc: 0.9844\n",
      "Epoch 18/500\n",
      "9142/9142 [==============================] - 2s 199us/step - loss: 0.0470 - acc: 0.9845 - val_loss: 0.0467 - val_acc: 0.9846\n",
      "Epoch 19/500\n",
      "9142/9142 [==============================] - 2s 199us/step - loss: 0.0469 - acc: 0.9846 - val_loss: 0.0464 - val_acc: 0.9845\n",
      "Epoch 20/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0466 - acc: 0.9847 - val_loss: 0.0461 - val_acc: 0.9847\n",
      "Epoch 21/500\n",
      "9142/9142 [==============================] - 2s 223us/step - loss: 0.0462 - acc: 0.9847 - val_loss: 0.0459 - val_acc: 0.9849\n",
      "Epoch 22/500\n",
      "9142/9142 [==============================] - 2s 204us/step - loss: 0.0461 - acc: 0.9847 - val_loss: 0.0457 - val_acc: 0.9850\n",
      "Epoch 23/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0458 - acc: 0.9848 - val_loss: 0.0454 - val_acc: 0.9849\n",
      "Epoch 24/500\n",
      "9142/9142 [==============================] - 2s 200us/step - loss: 0.0456 - acc: 0.9849 - val_loss: 0.0452 - val_acc: 0.9849\n",
      "Epoch 25/500\n",
      "9142/9142 [==============================] - 2s 212us/step - loss: 0.0455 - acc: 0.9849 - val_loss: 0.0451 - val_acc: 0.9849\n",
      "Epoch 26/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0451 - acc: 0.9851 - val_loss: 0.0449 - val_acc: 0.9849\n",
      "Epoch 27/500\n",
      "9142/9142 [==============================] - 2s 203us/step - loss: 0.0451 - acc: 0.9850 - val_loss: 0.0447 - val_acc: 0.9850\n",
      "Epoch 28/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0450 - acc: 0.9850 - val_loss: 0.0446 - val_acc: 0.9851\n",
      "Epoch 29/500\n",
      "9142/9142 [==============================] - 2s 204us/step - loss: 0.0447 - acc: 0.9852 - val_loss: 0.0443 - val_acc: 0.9852\n",
      "Epoch 30/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0445 - acc: 0.9850 - val_loss: 0.0442 - val_acc: 0.9851\n",
      "Epoch 31/500\n",
      "9142/9142 [==============================] - 2s 202us/step - loss: 0.0445 - acc: 0.9850 - val_loss: 0.0441 - val_acc: 0.9852\n",
      "Epoch 32/500\n",
      "9142/9142 [==============================] - 2s 202us/step - loss: 0.0443 - acc: 0.9852 - val_loss: 0.0439 - val_acc: 0.9854\n",
      "Epoch 33/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0441 - acc: 0.9851 - val_loss: 0.0438 - val_acc: 0.9853\n",
      "Epoch 34/500\n",
      "9142/9142 [==============================] - 2s 203us/step - loss: 0.0441 - acc: 0.9852 - val_loss: 0.0436 - val_acc: 0.9854\n",
      "Epoch 35/500\n",
      "9142/9142 [==============================] - 2s 202us/step - loss: 0.0440 - acc: 0.9852 - val_loss: 0.0436 - val_acc: 0.9853\n",
      "Epoch 36/500\n",
      "9142/9142 [==============================] - 2s 202us/step - loss: 0.0439 - acc: 0.9852 - val_loss: 0.0436 - val_acc: 0.9852\n",
      "Epoch 37/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0437 - acc: 0.9852 - val_loss: 0.0433 - val_acc: 0.9855\n",
      "Epoch 38/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0436 - acc: 0.9852 - val_loss: 0.0433 - val_acc: 0.9855\n",
      "Epoch 39/500\n",
      "9142/9142 [==============================] - 2s 208us/step - loss: 0.0435 - acc: 0.9854 - val_loss: 0.0431 - val_acc: 0.9855\n",
      "Epoch 40/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0434 - acc: 0.9853 - val_loss: 0.0429 - val_acc: 0.9856\n",
      "Epoch 41/500\n",
      "9142/9142 [==============================] - 2s 218us/step - loss: 0.0432 - acc: 0.9853 - val_loss: 0.0430 - val_acc: 0.9854\n",
      "Epoch 42/500\n",
      "9142/9142 [==============================] - 2s 203us/step - loss: 0.0431 - acc: 0.9854 - val_loss: 0.0429 - val_acc: 0.9855\n",
      "Epoch 43/500\n",
      "9142/9142 [==============================] - 2s 202us/step - loss: 0.0430 - acc: 0.9854 - val_loss: 0.0427 - val_acc: 0.9856\n",
      "Epoch 44/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0428 - acc: 0.9855 - val_loss: 0.0425 - val_acc: 0.9855\n",
      "Epoch 45/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0429 - acc: 0.9854 - val_loss: 0.0424 - val_acc: 0.9856\n",
      "Epoch 46/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0427 - acc: 0.9855 - val_loss: 0.0423 - val_acc: 0.9857\n",
      "Epoch 47/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0427 - acc: 0.9854 - val_loss: 0.0425 - val_acc: 0.9856\n",
      "Epoch 48/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0425 - acc: 0.9855 - val_loss: 0.0422 - val_acc: 0.9855\n",
      "Epoch 49/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0422 - acc: 0.9856 - val_loss: 0.0422 - val_acc: 0.9854\n",
      "Epoch 50/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0422 - acc: 0.9855 - val_loss: 0.0421 - val_acc: 0.9856\n",
      "Epoch 51/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0422 - acc: 0.9856 - val_loss: 0.0420 - val_acc: 0.9856\n",
      "Epoch 52/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0421 - acc: 0.9856 - val_loss: 0.0418 - val_acc: 0.9857\n",
      "Epoch 53/500\n",
      "9142/9142 [==============================] - 2s 246us/step - loss: 0.0419 - acc: 0.9857 - val_loss: 0.0419 - val_acc: 0.9858\n",
      "Epoch 54/500\n",
      "9142/9142 [==============================] - 2s 204us/step - loss: 0.0418 - acc: 0.9857 - val_loss: 0.0417 - val_acc: 0.9857\n",
      "Epoch 55/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0418 - acc: 0.9857 - val_loss: 0.0419 - val_acc: 0.9856\n",
      "Epoch 56/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0416 - acc: 0.9856 - val_loss: 0.0415 - val_acc: 0.9857\n",
      "Epoch 57/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0415 - acc: 0.9856 - val_loss: 0.0414 - val_acc: 0.9858\n",
      "Epoch 58/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0414 - acc: 0.9857 - val_loss: 0.0414 - val_acc: 0.9857\n",
      "Epoch 59/500\n",
      "9142/9142 [==============================] - 2s 210us/step - loss: 0.0412 - acc: 0.9858 - val_loss: 0.0414 - val_acc: 0.9856\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0412 - acc: 0.9858 - val_loss: 0.0415 - val_acc: 0.9857\n",
      "Epoch 61/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0411 - acc: 0.9857 - val_loss: 0.0412 - val_acc: 0.9857\n",
      "Epoch 62/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0410 - acc: 0.9858 - val_loss: 0.0411 - val_acc: 0.9858\n",
      "Epoch 63/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0410 - acc: 0.9858 - val_loss: 0.0410 - val_acc: 0.9858\n",
      "Epoch 64/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0407 - acc: 0.9858 - val_loss: 0.0409 - val_acc: 0.9857\n",
      "Epoch 65/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0407 - acc: 0.9858 - val_loss: 0.0408 - val_acc: 0.9857\n",
      "Epoch 66/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0406 - acc: 0.9860 - val_loss: 0.0407 - val_acc: 0.9859\n",
      "Epoch 67/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0405 - acc: 0.9859 - val_loss: 0.0407 - val_acc: 0.9859\n",
      "Epoch 68/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0405 - acc: 0.9858 - val_loss: 0.0407 - val_acc: 0.9858\n",
      "Epoch 69/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0404 - acc: 0.9859 - val_loss: 0.0407 - val_acc: 0.9858\n",
      "Epoch 70/500\n",
      "9142/9142 [==============================] - 2s 189us/step - loss: 0.0404 - acc: 0.9858 - val_loss: 0.0406 - val_acc: 0.9858\n",
      "Epoch 71/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0402 - acc: 0.9859 - val_loss: 0.0404 - val_acc: 0.9860\n",
      "Epoch 72/500\n",
      "9142/9142 [==============================] - 2s 197us/step - loss: 0.0404 - acc: 0.9859 - val_loss: 0.0404 - val_acc: 0.9860\n",
      "Epoch 73/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0402 - acc: 0.9860 - val_loss: 0.0404 - val_acc: 0.9859\n",
      "Epoch 74/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0399 - acc: 0.9860 - val_loss: 0.0404 - val_acc: 0.9860\n",
      "Epoch 75/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0400 - acc: 0.9861 - val_loss: 0.0404 - val_acc: 0.9859\n",
      "Epoch 76/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0400 - acc: 0.9860 - val_loss: 0.0400 - val_acc: 0.9858\n",
      "Epoch 77/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0398 - acc: 0.9860 - val_loss: 0.0400 - val_acc: 0.9860\n",
      "Epoch 78/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0398 - acc: 0.9861 - val_loss: 0.0401 - val_acc: 0.9859\n",
      "Epoch 79/500\n",
      "9142/9142 [==============================] - 2s 189us/step - loss: 0.0397 - acc: 0.9861 - val_loss: 0.0400 - val_acc: 0.9859\n",
      "Epoch 80/500\n",
      "9142/9142 [==============================] - 2s 208us/step - loss: 0.0397 - acc: 0.9860 - val_loss: 0.0401 - val_acc: 0.9859\n",
      "Epoch 81/500\n",
      "9142/9142 [==============================] - 2s 202us/step - loss: 0.0396 - acc: 0.9862 - val_loss: 0.0400 - val_acc: 0.9861\n",
      "Epoch 82/500\n",
      "9142/9142 [==============================] - 2s 202us/step - loss: 0.0394 - acc: 0.9862 - val_loss: 0.0399 - val_acc: 0.9860\n",
      "Epoch 83/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0395 - acc: 0.9861 - val_loss: 0.0400 - val_acc: 0.9860\n",
      "Epoch 84/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0395 - acc: 0.9861 - val_loss: 0.0398 - val_acc: 0.9859\n",
      "Epoch 85/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0395 - acc: 0.9861 - val_loss: 0.0398 - val_acc: 0.9860\n",
      "Epoch 86/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0394 - acc: 0.9861 - val_loss: 0.0396 - val_acc: 0.9862\n",
      "Epoch 87/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0394 - acc: 0.9862 - val_loss: 0.0397 - val_acc: 0.9861\n",
      "Epoch 88/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0393 - acc: 0.9861 - val_loss: 0.0396 - val_acc: 0.9861\n",
      "Epoch 89/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0392 - acc: 0.9862 - val_loss: 0.0397 - val_acc: 0.9862\n",
      "Epoch 90/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0392 - acc: 0.9862 - val_loss: 0.0396 - val_acc: 0.9860\n",
      "Epoch 91/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0392 - acc: 0.9862 - val_loss: 0.0395 - val_acc: 0.9861\n",
      "Epoch 92/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0392 - acc: 0.9863 - val_loss: 0.0395 - val_acc: 0.9860\n",
      "Epoch 93/500\n",
      "9142/9142 [==============================] - 2s 199us/step - loss: 0.0392 - acc: 0.9861 - val_loss: 0.0394 - val_acc: 0.9862\n",
      "Epoch 94/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0391 - acc: 0.9862 - val_loss: 0.0396 - val_acc: 0.9861\n",
      "Epoch 95/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0390 - acc: 0.9862 - val_loss: 0.0396 - val_acc: 0.9862\n",
      "Epoch 96/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0390 - acc: 0.9862 - val_loss: 0.0393 - val_acc: 0.9862\n",
      "Epoch 97/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0390 - acc: 0.9862 - val_loss: 0.0394 - val_acc: 0.9862\n",
      "Epoch 98/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0389 - acc: 0.9863 - val_loss: 0.0394 - val_acc: 0.9862\n",
      "Epoch 99/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0389 - acc: 0.9863 - val_loss: 0.0393 - val_acc: 0.9861\n",
      "Epoch 100/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0388 - acc: 0.9864 - val_loss: 0.0394 - val_acc: 0.9861\n",
      "Epoch 101/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0388 - acc: 0.9863 - val_loss: 0.0394 - val_acc: 0.9861\n",
      "Epoch 102/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0387 - acc: 0.9862 - val_loss: 0.0393 - val_acc: 0.9862\n",
      "Epoch 103/500\n",
      "9142/9142 [==============================] - 2s 189us/step - loss: 0.0388 - acc: 0.9863 - val_loss: 0.0393 - val_acc: 0.9861\n",
      "Epoch 104/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0386 - acc: 0.9862 - val_loss: 0.0395 - val_acc: 0.9860\n",
      "Epoch 105/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0387 - acc: 0.9863 - val_loss: 0.0393 - val_acc: 0.9860\n",
      "Epoch 106/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0387 - acc: 0.9863 - val_loss: 0.0394 - val_acc: 0.9862\n",
      "Epoch 107/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0385 - acc: 0.9864 - val_loss: 0.0393 - val_acc: 0.9862\n",
      "Epoch 108/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0386 - acc: 0.9864 - val_loss: 0.0392 - val_acc: 0.9863\n",
      "Epoch 109/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0385 - acc: 0.9864 - val_loss: 0.0392 - val_acc: 0.9862\n",
      "Epoch 110/500\n",
      "9142/9142 [==============================] - 2s 197us/step - loss: 0.0384 - acc: 0.9864 - val_loss: 0.0393 - val_acc: 0.9862\n",
      "Epoch 111/500\n",
      "9142/9142 [==============================] - 2s 202us/step - loss: 0.0384 - acc: 0.9865 - val_loss: 0.0392 - val_acc: 0.9861\n",
      "Epoch 112/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0385 - acc: 0.9863 - val_loss: 0.0391 - val_acc: 0.9864\n",
      "Epoch 113/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0383 - acc: 0.9863 - val_loss: 0.0393 - val_acc: 0.9862\n",
      "Epoch 114/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0384 - acc: 0.9864 - val_loss: 0.0392 - val_acc: 0.9862\n",
      "Epoch 115/500\n",
      "9142/9142 [==============================] - 2s 211us/step - loss: 0.0383 - acc: 0.9864 - val_loss: 0.0391 - val_acc: 0.9863\n",
      "Epoch 116/500\n",
      "9142/9142 [==============================] - 2s 200us/step - loss: 0.0385 - acc: 0.9864 - val_loss: 0.0392 - val_acc: 0.9862\n",
      "Epoch 117/500\n",
      "9142/9142 [==============================] - 2s 199us/step - loss: 0.0383 - acc: 0.9863 - val_loss: 0.0390 - val_acc: 0.9863\n",
      "Epoch 118/500\n",
      "9142/9142 [==============================] - 2s 199us/step - loss: 0.0384 - acc: 0.9863 - val_loss: 0.0391 - val_acc: 0.9863\n",
      "Epoch 119/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0383 - acc: 0.9864 - val_loss: 0.0389 - val_acc: 0.9863\n",
      "Epoch 120/500\n",
      "9142/9142 [==============================] - 2s 212us/step - loss: 0.0383 - acc: 0.9864 - val_loss: 0.0391 - val_acc: 0.9862\n",
      "Epoch 121/500\n",
      "9142/9142 [==============================] - 2s 188us/step - loss: 0.0382 - acc: 0.9864 - val_loss: 0.0390 - val_acc: 0.9862\n",
      "Epoch 122/500\n",
      "9142/9142 [==============================] - 2s 190us/step - loss: 0.0383 - acc: 0.9864 - val_loss: 0.0391 - val_acc: 0.9863\n",
      "Epoch 123/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0382 - acc: 0.9863 - val_loss: 0.0390 - val_acc: 0.9863\n",
      "Epoch 124/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0382 - acc: 0.9865 - val_loss: 0.0390 - val_acc: 0.9863\n",
      "Epoch 125/500\n",
      "9142/9142 [==============================] - 2s 244us/step - loss: 0.0380 - acc: 0.9864 - val_loss: 0.0391 - val_acc: 0.9861\n",
      "Epoch 126/500\n",
      "9142/9142 [==============================] - 2s 245us/step - loss: 0.0380 - acc: 0.9865 - val_loss: 0.0390 - val_acc: 0.9862\n",
      "Epoch 127/500\n",
      "9142/9142 [==============================] - 2s 245us/step - loss: 0.0383 - acc: 0.9864 - val_loss: 0.0389 - val_acc: 0.9864\n",
      "Epoch 128/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0381 - acc: 0.9864 - val_loss: 0.0390 - val_acc: 0.9864\n",
      "Epoch 129/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0380 - acc: 0.9864 - val_loss: 0.0390 - val_acc: 0.9864\n",
      "Epoch 130/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0380 - acc: 0.9865 - val_loss: 0.0389 - val_acc: 0.9862\n",
      "Epoch 131/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0379 - acc: 0.9864 - val_loss: 0.0389 - val_acc: 0.9863\n",
      "Epoch 132/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0380 - acc: 0.9864 - val_loss: 0.0391 - val_acc: 0.9863\n",
      "Epoch 133/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0380 - acc: 0.9865 - val_loss: 0.0389 - val_acc: 0.9862\n",
      "Epoch 134/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0380 - acc: 0.9864 - val_loss: 0.0389 - val_acc: 0.9863\n",
      "Epoch 135/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0378 - acc: 0.9865 - val_loss: 0.0389 - val_acc: 0.9861\n",
      "Epoch 136/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0377 - acc: 0.9865 - val_loss: 0.0389 - val_acc: 0.9863\n",
      "Epoch 137/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0380 - acc: 0.9865 - val_loss: 0.0389 - val_acc: 0.9862\n",
      "Epoch 138/500\n",
      "9142/9142 [==============================] - 2s 188us/step - loss: 0.0379 - acc: 0.9865 - val_loss: 0.0388 - val_acc: 0.9863\n",
      "Epoch 139/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0378 - acc: 0.9865 - val_loss: 0.0388 - val_acc: 0.9863\n",
      "Epoch 140/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0380 - acc: 0.9864 - val_loss: 0.0389 - val_acc: 0.9863\n",
      "Epoch 141/500\n",
      "9142/9142 [==============================] - 2s 208us/step - loss: 0.0378 - acc: 0.9864 - val_loss: 0.0390 - val_acc: 0.9862\n",
      "Epoch 142/500\n",
      "9142/9142 [==============================] - 2s 211us/step - loss: 0.0378 - acc: 0.9864 - val_loss: 0.0388 - val_acc: 0.9861\n",
      "Epoch 143/500\n",
      "9142/9142 [==============================] - 2s 228us/step - loss: 0.0376 - acc: 0.9865 - val_loss: 0.0386 - val_acc: 0.9865\n",
      "Epoch 144/500\n",
      "9142/9142 [==============================] - 2s 210us/step - loss: 0.0378 - acc: 0.9865 - val_loss: 0.0388 - val_acc: 0.9863\n",
      "Epoch 145/500\n",
      "9142/9142 [==============================] - 2s 236us/step - loss: 0.0377 - acc: 0.9866 - val_loss: 0.0390 - val_acc: 0.9863\n",
      "Epoch 146/500\n",
      "9142/9142 [==============================] - 2s 246us/step - loss: 0.0377 - acc: 0.9865 - val_loss: 0.0386 - val_acc: 0.9864\n",
      "Epoch 147/500\n",
      "9142/9142 [==============================] - 2s 220us/step - loss: 0.0376 - acc: 0.9866 - val_loss: 0.0387 - val_acc: 0.9864\n",
      "Epoch 148/500\n",
      "9142/9142 [==============================] - 2s 232us/step - loss: 0.0378 - acc: 0.9863 - val_loss: 0.0388 - val_acc: 0.9864\n",
      "Epoch 149/500\n",
      "9142/9142 [==============================] - 2s 219us/step - loss: 0.0375 - acc: 0.9864 - val_loss: 0.0388 - val_acc: 0.9864\n",
      "Epoch 150/500\n",
      "9142/9142 [==============================] - 2s 217us/step - loss: 0.0377 - acc: 0.9865 - val_loss: 0.0388 - val_acc: 0.9863\n",
      "Epoch 151/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0377 - acc: 0.9865 - val_loss: 0.0389 - val_acc: 0.9864\n",
      "Epoch 152/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0375 - acc: 0.9865 - val_loss: 0.0388 - val_acc: 0.9863\n",
      "Epoch 153/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0376 - acc: 0.9865 - val_loss: 0.0387 - val_acc: 0.9864\n",
      "Epoch 154/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0375 - acc: 0.9865 - val_loss: 0.0387 - val_acc: 0.9863\n",
      "Epoch 155/500\n",
      "9142/9142 [==============================] - 2s 213us/step - loss: 0.0376 - acc: 0.9866 - val_loss: 0.0387 - val_acc: 0.9862\n",
      "Epoch 156/500\n",
      "9142/9142 [==============================] - 2s 198us/step - loss: 0.0374 - acc: 0.9865 - val_loss: 0.0388 - val_acc: 0.9864\n",
      "Epoch 157/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0374 - acc: 0.9865 - val_loss: 0.0387 - val_acc: 0.9863\n",
      "Epoch 158/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0375 - acc: 0.9865 - val_loss: 0.0385 - val_acc: 0.9864\n",
      "Epoch 159/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0375 - acc: 0.9867 - val_loss: 0.0386 - val_acc: 0.9863\n",
      "Epoch 160/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0373 - acc: 0.9867 - val_loss: 0.0386 - val_acc: 0.9864\n",
      "Epoch 161/500\n",
      "9142/9142 [==============================] - 2s 199us/step - loss: 0.0373 - acc: 0.9866 - val_loss: 0.0385 - val_acc: 0.9864\n",
      "Epoch 162/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0375 - acc: 0.9866 - val_loss: 0.0387 - val_acc: 0.9863\n",
      "Epoch 163/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0374 - acc: 0.9867 - val_loss: 0.0386 - val_acc: 0.9863\n",
      "Epoch 164/500\n",
      "9142/9142 [==============================] - 2s 208us/step - loss: 0.0374 - acc: 0.9865 - val_loss: 0.0385 - val_acc: 0.9864\n",
      "Epoch 165/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0375 - acc: 0.9865 - val_loss: 0.0386 - val_acc: 0.9864\n",
      "Epoch 166/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0372 - acc: 0.9865 - val_loss: 0.0386 - val_acc: 0.9864\n",
      "Epoch 167/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0373 - acc: 0.9866 - val_loss: 0.0386 - val_acc: 0.9864\n",
      "Epoch 168/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0374 - acc: 0.9866 - val_loss: 0.0386 - val_acc: 0.9864\n",
      "Epoch 169/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0374 - acc: 0.9865 - val_loss: 0.0386 - val_acc: 0.9863\n",
      "Epoch 170/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0373 - acc: 0.9865 - val_loss: 0.0384 - val_acc: 0.9864\n",
      "Epoch 171/500\n",
      "9142/9142 [==============================] - 2s 190us/step - loss: 0.0372 - acc: 0.9867 - val_loss: 0.0384 - val_acc: 0.9866\n",
      "Epoch 172/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0372 - acc: 0.9866 - val_loss: 0.0386 - val_acc: 0.9863\n",
      "Epoch 173/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0371 - acc: 0.9867 - val_loss: 0.0387 - val_acc: 0.9864\n",
      "Epoch 174/500\n",
      "9142/9142 [==============================] - 2s 222us/step - loss: 0.0371 - acc: 0.9866 - val_loss: 0.0385 - val_acc: 0.9865\n",
      "Epoch 175/500\n",
      "9142/9142 [==============================] - 2s 212us/step - loss: 0.0371 - acc: 0.9867 - val_loss: 0.0386 - val_acc: 0.9864\n",
      "Epoch 176/500\n",
      "9142/9142 [==============================] - 2s 211us/step - loss: 0.0370 - acc: 0.9866 - val_loss: 0.0387 - val_acc: 0.9864\n",
      "Epoch 177/500\n",
      "9142/9142 [==============================] - 2s 199us/step - loss: 0.0371 - acc: 0.9866 - val_loss: 0.0387 - val_acc: 0.9864\n",
      "Epoch 178/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9142/9142 [==============================] - 2s 190us/step - loss: 0.0371 - acc: 0.9866 - val_loss: 0.0386 - val_acc: 0.9865\n",
      "Epoch 179/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0370 - acc: 0.9867 - val_loss: 0.0388 - val_acc: 0.9863: 0.036\n",
      "Epoch 180/500\n",
      "9142/9142 [==============================] - 2s 226us/step - loss: 0.0369 - acc: 0.9867 - val_loss: 0.0385 - val_acc: 0.9865\n",
      "Epoch 181/500\n",
      "9142/9142 [==============================] - 2s 235us/step - loss: 0.0369 - acc: 0.9868 - val_loss: 0.0387 - val_acc: 0.9864\n",
      "Epoch 182/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0371 - acc: 0.9866 - val_loss: 0.0385 - val_acc: 0.9864\n",
      "Epoch 183/500\n",
      "9142/9142 [==============================] - 2s 226us/step - loss: 0.0370 - acc: 0.9867 - val_loss: 0.0384 - val_acc: 0.9864\n",
      "Epoch 184/500\n",
      "9142/9142 [==============================] - 2s 221us/step - loss: 0.0370 - acc: 0.9866 - val_loss: 0.0384 - val_acc: 0.9865\n",
      "Epoch 185/500\n",
      "9142/9142 [==============================] - 2s 177us/step - loss: 0.0368 - acc: 0.9866 - val_loss: 0.0385 - val_acc: 0.9864\n",
      "Epoch 186/500\n",
      "9142/9142 [==============================] - 2s 175us/step - loss: 0.0368 - acc: 0.9867 - val_loss: 0.0384 - val_acc: 0.9864\n",
      "Epoch 187/500\n",
      "9142/9142 [==============================] - 2s 177us/step - loss: 0.0370 - acc: 0.9866 - val_loss: 0.0386 - val_acc: 0.9866\n",
      "Epoch 188/500\n",
      "9142/9142 [==============================] - 2s 177us/step - loss: 0.0369 - acc: 0.9866 - val_loss: 0.0384 - val_acc: 0.9865\n",
      "Epoch 189/500\n",
      "9142/9142 [==============================] - 2s 189us/step - loss: 0.0369 - acc: 0.9866 - val_loss: 0.0383 - val_acc: 0.9864\n",
      "Epoch 190/500\n",
      "9142/9142 [==============================] - 2s 197us/step - loss: 0.0370 - acc: 0.9868 - val_loss: 0.0384 - val_acc: 0.9864\n",
      "Epoch 191/500\n",
      "9142/9142 [==============================] - 2s 246us/step - loss: 0.0369 - acc: 0.9866 - val_loss: 0.0383 - val_acc: 0.9866\n",
      "Epoch 192/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0369 - acc: 0.9868 - val_loss: 0.0383 - val_acc: 0.9866\n",
      "Epoch 193/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0369 - acc: 0.9866 - val_loss: 0.0383 - val_acc: 0.9864\n",
      "Epoch 194/500\n",
      "9142/9142 [==============================] - 2s 211us/step - loss: 0.0369 - acc: 0.9866 - val_loss: 0.0384 - val_acc: 0.9865\n",
      "Epoch 195/500\n",
      "9142/9142 [==============================] - 2s 200us/step - loss: 0.0367 - acc: 0.9867 - val_loss: 0.0384 - val_acc: 0.9865\n",
      "Epoch 196/500\n",
      "9142/9142 [==============================] - 2s 211us/step - loss: 0.0368 - acc: 0.9867 - val_loss: 0.0382 - val_acc: 0.9865\n",
      "Epoch 197/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0367 - acc: 0.9867 - val_loss: 0.0383 - val_acc: 0.9865\n",
      "Epoch 198/500\n",
      "9142/9142 [==============================] - 2s 222us/step - loss: 0.0368 - acc: 0.9867 - val_loss: 0.0383 - val_acc: 0.9862\n",
      "Epoch 199/500\n",
      "9142/9142 [==============================] - 2s 213us/step - loss: 0.0368 - acc: 0.9867 - val_loss: 0.0382 - val_acc: 0.9866\n",
      "Epoch 200/500\n",
      "9142/9142 [==============================] - 2s 197us/step - loss: 0.0368 - acc: 0.9866 - val_loss: 0.0383 - val_acc: 0.9864\n",
      "Epoch 201/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0366 - acc: 0.9868 - val_loss: 0.0383 - val_acc: 0.9866\n",
      "Epoch 202/500\n",
      "9142/9142 [==============================] - 2s 189us/step - loss: 0.0367 - acc: 0.9867 - val_loss: 0.0384 - val_acc: 0.9864\n",
      "Epoch 203/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0367 - acc: 0.9867 - val_loss: 0.0382 - val_acc: 0.9866\n",
      "Epoch 204/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0367 - acc: 0.9867 - val_loss: 0.0382 - val_acc: 0.9865\n",
      "Epoch 205/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0366 - acc: 0.9868 - val_loss: 0.0383 - val_acc: 0.9864\n",
      "Epoch 206/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0367 - acc: 0.9866 - val_loss: 0.0381 - val_acc: 0.9865\n",
      "Epoch 207/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0366 - acc: 0.9869 - val_loss: 0.0382 - val_acc: 0.9864\n",
      "Epoch 208/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0365 - acc: 0.9868 - val_loss: 0.0385 - val_acc: 0.9862\n",
      "Epoch 209/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0366 - acc: 0.9866 - val_loss: 0.0385 - val_acc: 0.9867\n",
      "Epoch 210/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0366 - acc: 0.9867 - val_loss: 0.0383 - val_acc: 0.9865\n",
      "Epoch 211/500\n",
      "9142/9142 [==============================] - 2s 239us/step - loss: 0.0366 - acc: 0.9867 - val_loss: 0.0383 - val_acc: 0.9864\n",
      "Epoch 212/500\n",
      "9142/9142 [==============================] - 2s 224us/step - loss: 0.0365 - acc: 0.9868 - val_loss: 0.0383 - val_acc: 0.9866\n",
      "Epoch 213/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0365 - acc: 0.9868 - val_loss: 0.0383 - val_acc: 0.9866\n",
      "Epoch 214/500\n",
      "9142/9142 [==============================] - 2s 222us/step - loss: 0.0366 - acc: 0.9867 - val_loss: 0.0383 - val_acc: 0.9864\n",
      "Epoch 215/500\n",
      "9142/9142 [==============================] - 2s 216us/step - loss: 0.0365 - acc: 0.9866 - val_loss: 0.0383 - val_acc: 0.9865\n",
      "Epoch 216/500\n",
      "9142/9142 [==============================] - 2s 237us/step - loss: 0.0365 - acc: 0.9868 - val_loss: 0.0384 - val_acc: 0.9863 loss: 0.0365 - acc: 0.9\n",
      "Epoch 217/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0364 - acc: 0.9868 - val_loss: 0.0383 - val_acc: 0.9865\n",
      "Epoch 218/500\n",
      "9142/9142 [==============================] - 2s 208us/step - loss: 0.0366 - acc: 0.9867 - val_loss: 0.0383 - val_acc: 0.9864\n",
      "Epoch 219/500\n",
      "9142/9142 [==============================] - 2s 209us/step - loss: 0.0365 - acc: 0.9867 - val_loss: 0.0385 - val_acc: 0.9863\n",
      "Epoch 220/500\n",
      "9142/9142 [==============================] - 2s 215us/step - loss: 0.0366 - acc: 0.9867 - val_loss: 0.0383 - val_acc: 0.9866\n",
      "Epoch 221/500\n",
      "9142/9142 [==============================] - 2s 210us/step - loss: 0.0365 - acc: 0.9867 - val_loss: 0.0383 - val_acc: 0.9864\n",
      "Epoch 222/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0365 - acc: 0.9868 - val_loss: 0.0381 - val_acc: 0.9866\n",
      "Epoch 223/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0364 - acc: 0.9868 - val_loss: 0.0382 - val_acc: 0.9864\n",
      "Epoch 224/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0365 - acc: 0.9867 - val_loss: 0.0382 - val_acc: 0.9867\n",
      "Epoch 225/500\n",
      "9142/9142 [==============================] - 2s 209us/step - loss: 0.0363 - acc: 0.9867 - val_loss: 0.0381 - val_acc: 0.9867\n",
      "Epoch 226/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0362 - acc: 0.9867 - val_loss: 0.0381 - val_acc: 0.9865\n",
      "Epoch 227/500\n",
      "9142/9142 [==============================] - 2s 210us/step - loss: 0.0364 - acc: 0.9867 - val_loss: 0.0383 - val_acc: 0.9864\n",
      "Epoch 228/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0364 - acc: 0.9867 - val_loss: 0.0381 - val_acc: 0.9866\n",
      "Epoch 229/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0364 - acc: 0.9869 - val_loss: 0.0382 - val_acc: 0.9866\n",
      "Epoch 230/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0363 - acc: 0.9869 - val_loss: 0.0382 - val_acc: 0.9865\n",
      "Epoch 231/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0364 - acc: 0.9869 - val_loss: 0.0383 - val_acc: 0.9866\n",
      "Epoch 232/500\n",
      "9142/9142 [==============================] - 2s 208us/step - loss: 0.0363 - acc: 0.9867 - val_loss: 0.0383 - val_acc: 0.9865\n",
      "Epoch 233/500\n",
      "9142/9142 [==============================] - 2s 211us/step - loss: 0.0364 - acc: 0.9868 - val_loss: 0.0380 - val_acc: 0.9867\n",
      "Epoch 234/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0365 - acc: 0.9867 - val_loss: 0.0381 - val_acc: 0.9865\n",
      "Epoch 235/500\n",
      "9142/9142 [==============================] - 2s 211us/step - loss: 0.0364 - acc: 0.9867 - val_loss: 0.0383 - val_acc: 0.9865\n",
      "Epoch 236/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0361 - acc: 0.9868 - val_loss: 0.0382 - val_acc: 0.9866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0362 - acc: 0.9868 - val_loss: 0.0384 - val_acc: 0.9864\n",
      "Epoch 238/500\n",
      "9142/9142 [==============================] - 2s 190us/step - loss: 0.0363 - acc: 0.9868 - val_loss: 0.0381 - val_acc: 0.9864\n",
      "Epoch 239/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0363 - acc: 0.9867 - val_loss: 0.0382 - val_acc: 0.9866\n",
      "Epoch 240/500\n",
      "9142/9142 [==============================] - 2s 190us/step - loss: 0.0363 - acc: 0.9868 - val_loss: 0.0384 - val_acc: 0.9864\n",
      "Epoch 241/500\n",
      "9142/9142 [==============================] - 2s 189us/step - loss: 0.0361 - acc: 0.9869 - val_loss: 0.0381 - val_acc: 0.9865\n",
      "Epoch 242/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0363 - acc: 0.9868 - val_loss: 0.0381 - val_acc: 0.9867\n",
      "Epoch 243/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0361 - acc: 0.9869 - val_loss: 0.0382 - val_acc: 0.9865\n",
      "Epoch 244/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0363 - acc: 0.9867 - val_loss: 0.0383 - val_acc: 0.9864\n",
      "Epoch 245/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0362 - acc: 0.9867 - val_loss: 0.0381 - val_acc: 0.9868\n",
      "Epoch 246/500\n",
      "9142/9142 [==============================] - 2s 190us/step - loss: 0.0363 - acc: 0.9868 - val_loss: 0.0380 - val_acc: 0.9868\n",
      "Epoch 247/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0362 - acc: 0.9868 - val_loss: 0.0386 - val_acc: 0.9864\n",
      "Epoch 248/500\n",
      "9142/9142 [==============================] - 2s 210us/step - loss: 0.0361 - acc: 0.9868 - val_loss: 0.0382 - val_acc: 0.9867\n",
      "Epoch 249/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0363 - acc: 0.9868 - val_loss: 0.0382 - val_acc: 0.9866\n",
      "Epoch 250/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0363 - acc: 0.9868 - val_loss: 0.0381 - val_acc: 0.9866\n",
      "Epoch 251/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0362 - acc: 0.9867 - val_loss: 0.0381 - val_acc: 0.9865\n",
      "Epoch 252/500\n",
      "9142/9142 [==============================] - 2s 199us/step - loss: 0.0360 - acc: 0.9868 - val_loss: 0.0381 - val_acc: 0.9867\n",
      "Epoch 253/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0361 - acc: 0.9868 - val_loss: 0.0382 - val_acc: 0.9869\n",
      "Epoch 254/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0362 - acc: 0.9868 - val_loss: 0.0383 - val_acc: 0.9867\n",
      "Epoch 255/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0360 - acc: 0.9869 - val_loss: 0.0381 - val_acc: 0.9867\n",
      "Epoch 256/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0361 - acc: 0.9868 - val_loss: 0.0381 - val_acc: 0.9867\n",
      "Epoch 257/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0361 - acc: 0.9869 - val_loss: 0.0381 - val_acc: 0.9867\n",
      "Epoch 258/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0361 - acc: 0.9868 - val_loss: 0.0382 - val_acc: 0.9867\n",
      "Epoch 259/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0362 - acc: 0.9868 - val_loss: 0.0382 - val_acc: 0.9868\n",
      "Epoch 260/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0361 - acc: 0.9868 - val_loss: 0.0383 - val_acc: 0.9866\n",
      "Epoch 261/500\n",
      "9142/9142 [==============================] - 2s 197us/step - loss: 0.0359 - acc: 0.9868 - val_loss: 0.0382 - val_acc: 0.9865\n",
      "Epoch 262/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0359 - acc: 0.9870 - val_loss: 0.0382 - val_acc: 0.9865\n",
      "Epoch 263/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0360 - acc: 0.9870 - val_loss: 0.0382 - val_acc: 0.9867\n",
      "Epoch 264/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0360 - acc: 0.9868 - val_loss: 0.0381 - val_acc: 0.9866\n",
      "Epoch 265/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0360 - acc: 0.9868 - val_loss: 0.0382 - val_acc: 0.9865\n",
      "Epoch 266/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0360 - acc: 0.9869 - val_loss: 0.0384 - val_acc: 0.9867\n",
      "Epoch 267/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0359 - acc: 0.9869 - val_loss: 0.0384 - val_acc: 0.9865\n",
      "Epoch 268/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0361 - acc: 0.9868 - val_loss: 0.0381 - val_acc: 0.9866\n",
      "Epoch 269/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0360 - acc: 0.9869 - val_loss: 0.0382 - val_acc: 0.9865\n",
      "Epoch 270/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0360 - acc: 0.9868 - val_loss: 0.0385 - val_acc: 0.9863\n",
      "Epoch 271/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0359 - acc: 0.9869 - val_loss: 0.0382 - val_acc: 0.9868\n",
      "Epoch 272/500\n",
      "9142/9142 [==============================] - 2s 197us/step - loss: 0.0358 - acc: 0.9868 - val_loss: 0.0384 - val_acc: 0.9866\n",
      "Epoch 273/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0358 - acc: 0.9868 - val_loss: 0.0384 - val_acc: 0.9866\n",
      "Epoch 274/500\n",
      "9142/9142 [==============================] - 2s 198us/step - loss: 0.0360 - acc: 0.9869 - val_loss: 0.0382 - val_acc: 0.9866\n",
      "Epoch 275/500\n",
      "9142/9142 [==============================] - 2s 211us/step - loss: 0.0360 - acc: 0.9869 - val_loss: 0.0382 - val_acc: 0.9866\n",
      "Epoch 276/500\n",
      "9142/9142 [==============================] - 2s 223us/step - loss: 0.0359 - acc: 0.9869 - val_loss: 0.0383 - val_acc: 0.9866\n",
      "Epoch 277/500\n",
      "9142/9142 [==============================] - 2s 238us/step - loss: 0.0359 - acc: 0.9869 - val_loss: 0.0384 - val_acc: 0.9864\n",
      "Epoch 278/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0358 - acc: 0.9868 - val_loss: 0.0383 - val_acc: 0.9868\n",
      "Epoch 279/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0358 - acc: 0.9869 - val_loss: 0.0383 - val_acc: 0.9867\n",
      "Epoch 280/500\n",
      "9142/9142 [==============================] - 2s 198us/step - loss: 0.0358 - acc: 0.9869 - val_loss: 0.0382 - val_acc: 0.9866\n",
      "Epoch 281/500\n",
      "9142/9142 [==============================] - 2s 222us/step - loss: 0.0359 - acc: 0.9869 - val_loss: 0.0382 - val_acc: 0.9867\n",
      "Epoch 282/500\n",
      "9142/9142 [==============================] - 2s 210us/step - loss: 0.0358 - acc: 0.9868 - val_loss: 0.0384 - val_acc: 0.9868\n",
      "Epoch 283/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0359 - acc: 0.9868 - val_loss: 0.0382 - val_acc: 0.9869\n",
      "Epoch 284/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0358 - acc: 0.9870 - val_loss: 0.0382 - val_acc: 0.9867\n",
      "Epoch 285/500\n",
      "9142/9142 [==============================] - 2s 204us/step - loss: 0.0358 - acc: 0.9868 - val_loss: 0.0382 - val_acc: 0.9866\n",
      "Epoch 286/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0356 - acc: 0.9869 - val_loss: 0.0381 - val_acc: 0.9869\n",
      "Epoch 287/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0358 - acc: 0.9869 - val_loss: 0.0383 - val_acc: 0.9866\n",
      "Epoch 288/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0357 - acc: 0.9869 - val_loss: 0.0380 - val_acc: 0.9867\n",
      "Epoch 289/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0359 - acc: 0.9869 - val_loss: 0.0381 - val_acc: 0.9869\n",
      "Epoch 290/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0357 - acc: 0.9870 - val_loss: 0.0382 - val_acc: 0.9867\n",
      "Epoch 291/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0358 - acc: 0.9869 - val_loss: 0.0383 - val_acc: 0.9868\n",
      "Epoch 292/500\n",
      "9142/9142 [==============================] - 2s 198us/step - loss: 0.0357 - acc: 0.9869 - val_loss: 0.0381 - val_acc: 0.9869\n",
      "Epoch 293/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0356 - acc: 0.9870 - val_loss: 0.0383 - val_acc: 0.9867\n",
      "Epoch 294/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0358 - acc: 0.9870 - val_loss: 0.0385 - val_acc: 0.9866\n",
      "Epoch 295/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0357 - acc: 0.9870 - val_loss: 0.0383 - val_acc: 0.9869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/500\n",
      "9142/9142 [==============================] - 2s 190us/step - loss: 0.0358 - acc: 0.9869 - val_loss: 0.0381 - val_acc: 0.9865\n",
      "Epoch 297/500\n",
      "9142/9142 [==============================] - 2s 190us/step - loss: 0.0356 - acc: 0.9871 - val_loss: 0.0383 - val_acc: 0.9869\n",
      "Epoch 298/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0356 - acc: 0.9869 - val_loss: 0.0384 - val_acc: 0.9867\n",
      "Epoch 299/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0357 - acc: 0.9869 - val_loss: 0.0383 - val_acc: 0.9868\n",
      "Epoch 300/500\n",
      "9142/9142 [==============================] - 2s 190us/step - loss: 0.0356 - acc: 0.9869 - val_loss: 0.0383 - val_acc: 0.9866\n",
      "Epoch 301/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0355 - acc: 0.9870 - val_loss: 0.0383 - val_acc: 0.9867\n",
      "Epoch 302/500\n",
      "9142/9142 [==============================] - 2s 188us/step - loss: 0.0356 - acc: 0.9870 - val_loss: 0.0381 - val_acc: 0.9865\n",
      "Epoch 303/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0356 - acc: 0.9869 - val_loss: 0.0383 - val_acc: 0.9868\n",
      "Epoch 304/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0355 - acc: 0.9869 - val_loss: 0.0383 - val_acc: 0.9868\n",
      "Epoch 305/500\n",
      "9142/9142 [==============================] - 2s 189us/step - loss: 0.0357 - acc: 0.9870 - val_loss: 0.0381 - val_acc: 0.9868\n",
      "Epoch 306/500\n",
      "9142/9142 [==============================] - 2s 189us/step - loss: 0.0356 - acc: 0.9869 - val_loss: 0.0381 - val_acc: 0.9867\n",
      "Epoch 307/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0356 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9868\n",
      "Epoch 308/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0359 - acc: 0.9868 - val_loss: 0.0382 - val_acc: 0.9868\n",
      "Epoch 309/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0357 - acc: 0.9870 - val_loss: 0.0383 - val_acc: 0.9869\n",
      "Epoch 310/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0356 - acc: 0.9870 - val_loss: 0.0383 - val_acc: 0.9867\n",
      "Epoch 311/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0355 - acc: 0.9870 - val_loss: 0.0379 - val_acc: 0.9868\n",
      "Epoch 312/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0356 - acc: 0.9868 - val_loss: 0.0382 - val_acc: 0.9866\n",
      "Epoch 313/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0358 - acc: 0.9869 - val_loss: 0.0383 - val_acc: 0.9869\n",
      "Epoch 314/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0356 - acc: 0.9870 - val_loss: 0.0383 - val_acc: 0.9869\n",
      "Epoch 315/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0355 - acc: 0.9870 - val_loss: 0.0386 - val_acc: 0.9867\n",
      "Epoch 316/500\n",
      "9142/9142 [==============================] - 2s 212us/step - loss: 0.0356 - acc: 0.9869 - val_loss: 0.0382 - val_acc: 0.9866\n",
      "Epoch 317/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0356 - acc: 0.9869 - val_loss: 0.0381 - val_acc: 0.9868\n",
      "Epoch 318/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0354 - acc: 0.9870 - val_loss: 0.0383 - val_acc: 0.9869\n",
      "Epoch 319/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0355 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9869\n",
      "Epoch 320/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0357 - acc: 0.9868 - val_loss: 0.0383 - val_acc: 0.9868\n",
      "Epoch 321/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0355 - acc: 0.9868 - val_loss: 0.0382 - val_acc: 0.9868\n",
      "Epoch 322/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0353 - acc: 0.9871 - val_loss: 0.0382 - val_acc: 0.9866\n",
      "Epoch 323/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0355 - acc: 0.9869 - val_loss: 0.0384 - val_acc: 0.9868\n",
      "Epoch 324/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0355 - acc: 0.9870 - val_loss: 0.0381 - val_acc: 0.9870\n",
      "Epoch 325/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0355 - acc: 0.9869 - val_loss: 0.0384 - val_acc: 0.9867\n",
      "Epoch 326/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0353 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9867\n",
      "Epoch 327/500\n",
      "9142/9142 [==============================] - 2s 204us/step - loss: 0.0356 - acc: 0.9868 - val_loss: 0.0384 - val_acc: 0.9867\n",
      "Epoch 328/500\n",
      "9142/9142 [==============================] - 2s 200us/step - loss: 0.0355 - acc: 0.9870 - val_loss: 0.0383 - val_acc: 0.9868\n",
      "Epoch 329/500\n",
      "9142/9142 [==============================] - 2s 197us/step - loss: 0.0354 - acc: 0.9872 - val_loss: 0.0383 - val_acc: 0.9869\n",
      "Epoch 330/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0355 - acc: 0.9870 - val_loss: 0.0383 - val_acc: 0.9868\n",
      "Epoch 331/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0353 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9867\n",
      "Epoch 332/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0354 - acc: 0.9870 - val_loss: 0.0383 - val_acc: 0.9866\n",
      "Epoch 333/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0355 - acc: 0.9869 - val_loss: 0.0385 - val_acc: 0.9866\n",
      "Epoch 334/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0354 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9867\n",
      "Epoch 335/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0353 - acc: 0.9870 - val_loss: 0.0383 - val_acc: 0.9868\n",
      "Epoch 336/500\n",
      "9142/9142 [==============================] - 2s 197us/step - loss: 0.0353 - acc: 0.9871 - val_loss: 0.0384 - val_acc: 0.9866\n",
      "Epoch 337/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0354 - acc: 0.9871 - val_loss: 0.0383 - val_acc: 0.9866\n",
      "Epoch 338/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0354 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9869\n",
      "Epoch 339/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0355 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9867\n",
      "Epoch 340/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0355 - acc: 0.9871 - val_loss: 0.0383 - val_acc: 0.9868\n",
      "Epoch 341/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0353 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9869\n",
      "Epoch 342/500\n",
      "9142/9142 [==============================] - 2s 208us/step - loss: 0.0354 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9867\n",
      "Epoch 343/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0352 - acc: 0.9871 - val_loss: 0.0385 - val_acc: 0.9867\n",
      "Epoch 344/500\n",
      "9142/9142 [==============================] - 2s 203us/step - loss: 0.0355 - acc: 0.9869 - val_loss: 0.0384 - val_acc: 0.9869\n",
      "Epoch 345/500\n",
      "9142/9142 [==============================] - 2s 197us/step - loss: 0.0354 - acc: 0.9871 - val_loss: 0.0384 - val_acc: 0.9865\n",
      "Epoch 346/500\n",
      "9142/9142 [==============================] - 2s 189us/step - loss: 0.0354 - acc: 0.9870 - val_loss: 0.0383 - val_acc: 0.9869\n",
      "Epoch 347/500\n",
      "9142/9142 [==============================] - 2s 200us/step - loss: 0.0353 - acc: 0.9870 - val_loss: 0.0383 - val_acc: 0.9868\n",
      "Epoch 348/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0352 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9867\n",
      "Epoch 349/500\n",
      "9142/9142 [==============================] - 2s 202us/step - loss: 0.0352 - acc: 0.9871 - val_loss: 0.0384 - val_acc: 0.9869\n",
      "Epoch 350/500\n",
      "9142/9142 [==============================] - 2s 197us/step - loss: 0.0353 - acc: 0.9871 - val_loss: 0.0382 - val_acc: 0.9869\n",
      "Epoch 351/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0353 - acc: 0.9870 - val_loss: 0.0385 - val_acc: 0.9867\n",
      "Epoch 352/500\n",
      "9142/9142 [==============================] - 2s 199us/step - loss: 0.0352 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9866\n",
      "Epoch 353/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0354 - acc: 0.9870 - val_loss: 0.0382 - val_acc: 0.9869\n",
      "Epoch 354/500\n",
      "9142/9142 [==============================] - 2s 198us/step - loss: 0.0353 - acc: 0.9871 - val_loss: 0.0383 - val_acc: 0.9866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/500\n",
      "9142/9142 [==============================] - 2s 190us/step - loss: 0.0353 - acc: 0.9869 - val_loss: 0.0386 - val_acc: 0.9866\n",
      "Epoch 356/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0352 - acc: 0.9871 - val_loss: 0.0384 - val_acc: 0.9869\n",
      "Epoch 357/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0353 - acc: 0.9870 - val_loss: 0.0387 - val_acc: 0.9870\n",
      "Epoch 358/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0353 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9866\n",
      "Epoch 359/500\n",
      "9142/9142 [==============================] - 2s 189us/step - loss: 0.0354 - acc: 0.9869 - val_loss: 0.0386 - val_acc: 0.9868\n",
      "Epoch 360/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0353 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9866\n",
      "Epoch 361/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0353 - acc: 0.9869 - val_loss: 0.0384 - val_acc: 0.9867\n",
      "Epoch 362/500\n",
      "9142/9142 [==============================] - 2s 190us/step - loss: 0.0351 - acc: 0.9871 - val_loss: 0.0384 - val_acc: 0.9869\n",
      "Epoch 363/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0352 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9869\n",
      "Epoch 364/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0353 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9867\n",
      "Epoch 365/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0351 - acc: 0.9870 - val_loss: 0.0386 - val_acc: 0.9867\n",
      "Epoch 366/500\n",
      "9142/9142 [==============================] - 2s 197us/step - loss: 0.0351 - acc: 0.9871 - val_loss: 0.0385 - val_acc: 0.9867\n",
      "Epoch 367/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0351 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9869\n",
      "Epoch 368/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0353 - acc: 0.9871 - val_loss: 0.0388 - val_acc: 0.9868\n",
      "Epoch 369/500\n",
      "9142/9142 [==============================] - 2s 191us/step - loss: 0.0352 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9869\n",
      "Epoch 370/500\n",
      "9142/9142 [==============================] - 2s 200us/step - loss: 0.0349 - acc: 0.9871 - val_loss: 0.0384 - val_acc: 0.9867\n",
      "Epoch 371/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0352 - acc: 0.9870 - val_loss: 0.0386 - val_acc: 0.9869\n",
      "Epoch 372/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0351 - acc: 0.9870 - val_loss: 0.0385 - val_acc: 0.9867\n",
      "Epoch 373/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0350 - acc: 0.9871 - val_loss: 0.0382 - val_acc: 0.9868\n",
      "Epoch 374/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0351 - acc: 0.9871 - val_loss: 0.0385 - val_acc: 0.9871\n",
      "Epoch 375/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0350 - acc: 0.9872 - val_loss: 0.0386 - val_acc: 0.9868\n",
      "Epoch 376/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0352 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9867\n",
      "Epoch 377/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0353 - acc: 0.9871 - val_loss: 0.0387 - val_acc: 0.9866\n",
      "Epoch 378/500\n",
      "9142/9142 [==============================] - 2s 199us/step - loss: 0.0351 - acc: 0.9871 - val_loss: 0.0385 - val_acc: 0.9869\n",
      "Epoch 379/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0352 - acc: 0.9870 - val_loss: 0.0386 - val_acc: 0.9867\n",
      "Epoch 380/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0351 - acc: 0.9872 - val_loss: 0.0386 - val_acc: 0.9867\n",
      "Epoch 381/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0352 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9868\n",
      "Epoch 382/500\n",
      "9142/9142 [==============================] - 2s 209us/step - loss: 0.0351 - acc: 0.9870 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 383/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0350 - acc: 0.9870 - val_loss: 0.0386 - val_acc: 0.9870\n",
      "Epoch 384/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0351 - acc: 0.9871 - val_loss: 0.0385 - val_acc: 0.9867\n",
      "Epoch 385/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0350 - acc: 0.9870 - val_loss: 0.0386 - val_acc: 0.9868\n",
      "Epoch 386/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0350 - acc: 0.9870 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 387/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0350 - acc: 0.9870 - val_loss: 0.0385 - val_acc: 0.9867\n",
      "Epoch 388/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0353 - acc: 0.9872 - val_loss: 0.0388 - val_acc: 0.9868\n",
      "Epoch 389/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0351 - acc: 0.9869 - val_loss: 0.0385 - val_acc: 0.9869\n",
      "Epoch 390/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0350 - acc: 0.9872 - val_loss: 0.0385 - val_acc: 0.9868\n",
      "Epoch 391/500\n",
      "9142/9142 [==============================] - 2s 204us/step - loss: 0.0349 - acc: 0.9870 - val_loss: 0.0385 - val_acc: 0.9866\n",
      "Epoch 392/500\n",
      "9142/9142 [==============================] - 2s 214us/step - loss: 0.0350 - acc: 0.9869 - val_loss: 0.0385 - val_acc: 0.9870\n",
      "Epoch 393/500\n",
      "9142/9142 [==============================] - 3s 306us/step - loss: 0.0349 - acc: 0.9871 - val_loss: 0.0387 - val_acc: 0.9866\n",
      "Epoch 394/500\n",
      "9142/9142 [==============================] - 2s 244us/step - loss: 0.0351 - acc: 0.9870 - val_loss: 0.0386 - val_acc: 0.9866\n",
      "Epoch 395/500\n",
      "9142/9142 [==============================] - 2s 247us/step - loss: 0.0350 - acc: 0.9871 - val_loss: 0.0385 - val_acc: 0.9869\n",
      "Epoch 396/500\n",
      "9142/9142 [==============================] - 2s 203us/step - loss: 0.0348 - acc: 0.9870 - val_loss: 0.0389 - val_acc: 0.9869\n",
      "Epoch 397/500\n",
      "9142/9142 [==============================] - 2s 177us/step - loss: 0.0351 - acc: 0.9871 - val_loss: 0.0385 - val_acc: 0.9867\n",
      "Epoch 398/500\n",
      "9142/9142 [==============================] - 2s 222us/step - loss: 0.0351 - acc: 0.9869 - val_loss: 0.0386 - val_acc: 0.9868\n",
      "Epoch 399/500\n",
      "9142/9142 [==============================] - 2s 234us/step - loss: 0.0349 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9869\n",
      "Epoch 400/500\n",
      "9142/9142 [==============================] - 2s 227us/step - loss: 0.0349 - acc: 0.9870 - val_loss: 0.0385 - val_acc: 0.9870\n",
      "Epoch 401/500\n",
      "9142/9142 [==============================] - 2s 225us/step - loss: 0.0350 - acc: 0.9870 - val_loss: 0.0388 - val_acc: 0.9867\n",
      "Epoch 402/500\n",
      "9142/9142 [==============================] - 2s 214us/step - loss: 0.0350 - acc: 0.9871 - val_loss: 0.0390 - val_acc: 0.9866\n",
      "Epoch 403/500\n",
      "9142/9142 [==============================] - 2s 214us/step - loss: 0.0350 - acc: 0.9870 - val_loss: 0.0386 - val_acc: 0.9870\n",
      "Epoch 404/500\n",
      "9142/9142 [==============================] - 2s 222us/step - loss: 0.0348 - acc: 0.9871 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 405/500\n",
      "9142/9142 [==============================] - 2s 202us/step - loss: 0.0350 - acc: 0.9871 - val_loss: 0.0383 - val_acc: 0.9870\n",
      "Epoch 406/500\n",
      "9142/9142 [==============================] - 2s 203us/step - loss: 0.0348 - acc: 0.9871 - val_loss: 0.0388 - val_acc: 0.9866\n",
      "Epoch 407/500\n",
      "9142/9142 [==============================] - 2s 221us/step - loss: 0.0351 - acc: 0.9871 - val_loss: 0.0387 - val_acc: 0.9870\n",
      "Epoch 408/500\n",
      "9142/9142 [==============================] - 2s 217us/step - loss: 0.0348 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9870\n",
      "Epoch 409/500\n",
      "9142/9142 [==============================] - 2s 209us/step - loss: 0.0349 - acc: 0.9870 - val_loss: 0.0390 - val_acc: 0.9870\n",
      "Epoch 410/500\n",
      "9142/9142 [==============================] - 2s 210us/step - loss: 0.0352 - acc: 0.9871 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 411/500\n",
      "9142/9142 [==============================] - 2s 199us/step - loss: 0.0349 - acc: 0.9870 - val_loss: 0.0385 - val_acc: 0.9869\n",
      "Epoch 412/500\n",
      "9142/9142 [==============================] - 2s 214us/step - loss: 0.0349 - acc: 0.9871 - val_loss: 0.0384 - val_acc: 0.9870\n",
      "Epoch 413/500\n",
      "9142/9142 [==============================] - 2s 208us/step - loss: 0.0348 - acc: 0.9872 - val_loss: 0.0390 - val_acc: 0.9868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0348 - acc: 0.9872 - val_loss: 0.0386 - val_acc: 0.9871\n",
      "Epoch 415/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0349 - acc: 0.9872 - val_loss: 0.0386 - val_acc: 0.9867\n",
      "Epoch 416/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0348 - acc: 0.9871 - val_loss: 0.0390 - val_acc: 0.9870\n",
      "Epoch 417/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0348 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9867\n",
      "Epoch 418/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0349 - acc: 0.9870 - val_loss: 0.0388 - val_acc: 0.9871\n",
      "Epoch 419/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0348 - acc: 0.9872 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 420/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0349 - acc: 0.9870 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 421/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0349 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9868\n",
      "Epoch 422/500\n",
      "9142/9142 [==============================] - 2s 197us/step - loss: 0.0348 - acc: 0.9872 - val_loss: 0.0387 - val_acc: 0.9866\n",
      "Epoch 423/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0349 - acc: 0.9871 - val_loss: 0.0388 - val_acc: 0.9869\n",
      "Epoch 424/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0348 - acc: 0.9872 - val_loss: 0.0386 - val_acc: 0.9870\n",
      "Epoch 425/500\n",
      "9142/9142 [==============================] - 2s 217us/step - loss: 0.0348 - acc: 0.9872 - val_loss: 0.0386 - val_acc: 0.9868\n",
      "Epoch 426/500\n",
      "9142/9142 [==============================] - 2s 209us/step - loss: 0.0348 - acc: 0.9871 - val_loss: 0.0389 - val_acc: 0.9870\n",
      "Epoch 427/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0348 - acc: 0.9871 - val_loss: 0.0388 - val_acc: 0.9866\n",
      "Epoch 428/500\n",
      "9142/9142 [==============================] - 2s 202us/step - loss: 0.0349 - acc: 0.9871 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 429/500\n",
      "9142/9142 [==============================] - 2s 202us/step - loss: 0.0348 - acc: 0.9870 - val_loss: 0.0389 - val_acc: 0.9870\n",
      "Epoch 430/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0348 - acc: 0.9871 - val_loss: 0.0388 - val_acc: 0.9867\n",
      "Epoch 431/500\n",
      "9142/9142 [==============================] - 2s 204us/step - loss: 0.0349 - acc: 0.9872 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 432/500\n",
      "9142/9142 [==============================] - 2s 200us/step - loss: 0.0349 - acc: 0.9871 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 433/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0348 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9871\n",
      "Epoch 434/500\n",
      "9142/9142 [==============================] - 2s 204us/step - loss: 0.0347 - acc: 0.9871 - val_loss: 0.0387 - val_acc: 0.9868\n",
      "Epoch 435/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0348 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9869\n",
      "Epoch 436/500\n",
      "9142/9142 [==============================] - 2s 204us/step - loss: 0.0348 - acc: 0.9872 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 437/500\n",
      "9142/9142 [==============================] - 2s 202us/step - loss: 0.0348 - acc: 0.9872 - val_loss: 0.0388 - val_acc: 0.9869\n",
      "Epoch 438/500\n",
      "9142/9142 [==============================] - 2s 200us/step - loss: 0.0348 - acc: 0.9872 - val_loss: 0.0386 - val_acc: 0.9869\n",
      "Epoch 439/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0347 - acc: 0.9871 - val_loss: 0.0389 - val_acc: 0.9869\n",
      "Epoch 440/500\n",
      "9142/9142 [==============================] - 2s 222us/step - loss: 0.0347 - acc: 0.9871 - val_loss: 0.0388 - val_acc: 0.9867\n",
      "Epoch 441/500\n",
      "9142/9142 [==============================] - 2s 217us/step - loss: 0.0346 - acc: 0.9873 - val_loss: 0.0388 - val_acc: 0.9868\n",
      "Epoch 442/500\n",
      "9142/9142 [==============================] - 2s 208us/step - loss: 0.0345 - acc: 0.9872 - val_loss: 0.0390 - val_acc: 0.9868\n",
      "Epoch 443/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0346 - acc: 0.9871 - val_loss: 0.0388 - val_acc: 0.9870\n",
      "Epoch 444/500\n",
      "9142/9142 [==============================] - 2s 209us/step - loss: 0.0347 - acc: 0.9871 - val_loss: 0.0389 - val_acc: 0.9869\n",
      "Epoch 445/500\n",
      "9142/9142 [==============================] - 2s 236us/step - loss: 0.0347 - acc: 0.9870 - val_loss: 0.0389 - val_acc: 0.9868\n",
      "Epoch 446/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0347 - acc: 0.9872 - val_loss: 0.0386 - val_acc: 0.9869\n",
      "Epoch 447/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0347 - acc: 0.9872 - val_loss: 0.0386 - val_acc: 0.9869\n",
      "Epoch 448/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0346 - acc: 0.9871 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 449/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0348 - acc: 0.9871 - val_loss: 0.0388 - val_acc: 0.9868\n",
      "Epoch 450/500\n",
      "9142/9142 [==============================] - 2s 204us/step - loss: 0.0346 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9870\n",
      "Epoch 451/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0347 - acc: 0.9872 - val_loss: 0.0389 - val_acc: 0.9869\n",
      "Epoch 452/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0345 - acc: 0.9872 - val_loss: 0.0387 - val_acc: 0.9872\n",
      "Epoch 453/500\n",
      "9142/9142 [==============================] - 2s 200us/step - loss: 0.0347 - acc: 0.9872 - val_loss: 0.0386 - val_acc: 0.9871\n",
      "Epoch 454/500\n",
      "9142/9142 [==============================] - 2s 246us/step - loss: 0.0347 - acc: 0.9871 - val_loss: 0.0387 - val_acc: 0.9870\n",
      "Epoch 455/500\n",
      "9142/9142 [==============================] - 2s 251us/step - loss: 0.0347 - acc: 0.9871 - val_loss: 0.0389 - val_acc: 0.9869\n",
      "Epoch 456/500\n",
      "9142/9142 [==============================] - 2s 251us/step - loss: 0.0347 - acc: 0.9873 - val_loss: 0.0389 - val_acc: 0.9867\n",
      "Epoch 457/500\n",
      "9142/9142 [==============================] - 2s 241us/step - loss: 0.0348 - acc: 0.9872 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 458/500\n",
      "9142/9142 [==============================] - 2s 202us/step - loss: 0.0346 - acc: 0.9872 - val_loss: 0.0390 - val_acc: 0.9869\n",
      "Epoch 459/500\n",
      "9142/9142 [==============================] - 2s 200us/step - loss: 0.0347 - acc: 0.9872 - val_loss: 0.0387 - val_acc: 0.9868\n",
      "Epoch 460/500\n",
      "9142/9142 [==============================] - 2s 204us/step - loss: 0.0347 - acc: 0.9873 - val_loss: 0.0388 - val_acc: 0.9870\n",
      "Epoch 461/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0347 - acc: 0.9871 - val_loss: 0.0387 - val_acc: 0.9871\n",
      "Epoch 462/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0347 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9870\n",
      "Epoch 463/500\n",
      "9142/9142 [==============================] - 2s 210us/step - loss: 0.0346 - acc: 0.9871 - val_loss: 0.0387 - val_acc: 0.9870\n",
      "Epoch 464/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0346 - acc: 0.9872 - val_loss: 0.0387 - val_acc: 0.9871\n",
      "Epoch 465/500\n",
      "9142/9142 [==============================] - 2s 207us/step - loss: 0.0348 - acc: 0.9871 - val_loss: 0.0388 - val_acc: 0.9871\n",
      "Epoch 466/500\n",
      "9142/9142 [==============================] - 2s 218us/step - loss: 0.0346 - acc: 0.9872 - val_loss: 0.0387 - val_acc: 0.9870\n",
      "Epoch 467/500\n",
      "9142/9142 [==============================] - 2s 205us/step - loss: 0.0344 - acc: 0.9873 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 468/500\n",
      "9142/9142 [==============================] - 2s 201us/step - loss: 0.0346 - acc: 0.9871 - val_loss: 0.0387 - val_acc: 0.9868\n",
      "Epoch 469/500\n",
      "9142/9142 [==============================] - 2s 220us/step - loss: 0.0347 - acc: 0.9872 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 470/500\n",
      "9142/9142 [==============================] - 2s 221us/step - loss: 0.0345 - acc: 0.9872 - val_loss: 0.0388 - val_acc: 0.9869\n",
      "Epoch 471/500\n",
      "9142/9142 [==============================] - 2s 212us/step - loss: 0.0345 - acc: 0.9871 - val_loss: 0.0389 - val_acc: 0.9869\n",
      "Epoch 472/500\n",
      "9142/9142 [==============================] - 2s 224us/step - loss: 0.0348 - acc: 0.9871 - val_loss: 0.0388 - val_acc: 0.9868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/500\n",
      "9142/9142 [==============================] - 2s 190us/step - loss: 0.0346 - acc: 0.9872 - val_loss: 0.0390 - val_acc: 0.9868\n",
      "Epoch 474/500\n",
      "9142/9142 [==============================] - 2s 190us/step - loss: 0.0344 - acc: 0.9872 - val_loss: 0.0387 - val_acc: 0.9872\n",
      "Epoch 475/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0345 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9868\n",
      "Epoch 476/500\n",
      "9142/9142 [==============================] - 2s 206us/step - loss: 0.0345 - acc: 0.9872 - val_loss: 0.0389 - val_acc: 0.9869\n",
      "Epoch 477/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0345 - acc: 0.9871 - val_loss: 0.0387 - val_acc: 0.9870\n",
      "Epoch 478/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0345 - acc: 0.9873 - val_loss: 0.0389 - val_acc: 0.9871\n",
      "Epoch 479/500\n",
      "9142/9142 [==============================] - 2s 190us/step - loss: 0.0345 - acc: 0.9873 - val_loss: 0.0390 - val_acc: 0.9868\n",
      "Epoch 480/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0344 - acc: 0.9872 - val_loss: 0.0387 - val_acc: 0.9870\n",
      "Epoch 481/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0347 - acc: 0.9871 - val_loss: 0.0389 - val_acc: 0.9870\n",
      "Epoch 482/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0345 - acc: 0.9872 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 483/500\n",
      "9142/9142 [==============================] - 2s 199us/step - loss: 0.0346 - acc: 0.9872 - val_loss: 0.0390 - val_acc: 0.9869\n",
      "Epoch 484/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0345 - acc: 0.9871 - val_loss: 0.0389 - val_acc: 0.9869\n",
      "Epoch 485/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0346 - acc: 0.9872 - val_loss: 0.0390 - val_acc: 0.9868\n",
      "Epoch 486/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0345 - acc: 0.9872 - val_loss: 0.0391 - val_acc: 0.9871\n",
      "Epoch 487/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0345 - acc: 0.9871 - val_loss: 0.0390 - val_acc: 0.9869\n",
      "Epoch 488/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0344 - acc: 0.9871 - val_loss: 0.0388 - val_acc: 0.9869\n",
      "Epoch 489/500\n",
      "9142/9142 [==============================] - 2s 214us/step - loss: 0.0343 - acc: 0.9872 - val_loss: 0.0389 - val_acc: 0.9871\n",
      "Epoch 490/500\n",
      "9142/9142 [==============================] - 2s 214us/step - loss: 0.0345 - acc: 0.9872 - val_loss: 0.0390 - val_acc: 0.9870\n",
      "Epoch 491/500\n",
      "9142/9142 [==============================] - 2s 218us/step - loss: 0.0343 - acc: 0.9873 - val_loss: 0.0390 - val_acc: 0.9867\n",
      "Epoch 492/500\n",
      "9142/9142 [==============================] - 2s 212us/step - loss: 0.0344 - acc: 0.9872 - val_loss: 0.0388 - val_acc: 0.9869\n",
      "Epoch 493/500\n",
      "9142/9142 [==============================] - 2s 196us/step - loss: 0.0344 - acc: 0.9873 - val_loss: 0.0388 - val_acc: 0.9870\n",
      "Epoch 494/500\n",
      "9142/9142 [==============================] - 2s 189us/step - loss: 0.0343 - acc: 0.9872 - val_loss: 0.0391 - val_acc: 0.9868\n",
      "Epoch 495/500\n",
      "9142/9142 [==============================] - 2s 192us/step - loss: 0.0344 - acc: 0.9872 - val_loss: 0.0391 - val_acc: 0.9871\n",
      "Epoch 496/500\n",
      "9142/9142 [==============================] - 2s 193us/step - loss: 0.0345 - acc: 0.9871 - val_loss: 0.0390 - val_acc: 0.9870\n",
      "Epoch 497/500\n",
      "9142/9142 [==============================] - 2s 195us/step - loss: 0.0343 - acc: 0.9872 - val_loss: 0.0387 - val_acc: 0.9869\n",
      "Epoch 498/500\n",
      "9142/9142 [==============================] - 2s 198us/step - loss: 0.0345 - acc: 0.9872 - val_loss: 0.0391 - val_acc: 0.9869\n",
      "Epoch 499/500\n",
      "9142/9142 [==============================] - 2s 194us/step - loss: 0.0343 - acc: 0.9872 - val_loss: 0.0389 - val_acc: 0.9868\n",
      "Epoch 500/500\n",
      "9142/9142 [==============================] - 2s 190us/step - loss: 0.0345 - acc: 0.9873 - val_loss: 0.0389 - val_acc: 0.9870\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(tr_data, tr_labels, epochs=500, validation_split=0.2,\n",
    "                    shuffle=True, batch_size=10, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1221/1221 [==============================] - 0s 38us/step\n",
      "\n",
      "acc: 98.57%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(te_data, te_labels)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"out_files/model.h5\")\n",
    "write_file(\"out_files/config.json\", model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
